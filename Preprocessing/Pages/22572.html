<!DOCTYPE html>

<!--[if lt IE 7]> <html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if IE 7]>    <html class="no-js lt-ie9 lt-ie8" lang="en"> <![endif]-->
<!--[if IE 8]>    <html class="no-js lt-ie9" lang="en"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="/xmlui/themes/Mirage2/images/favicon.ico" rel="shortcut icon"/>
<link href="/xmlui/themes/Mirage2/images/apple-touch-icon.png" rel="apple-touch-icon"/>
<meta content="DSpace 5.8" name="Generator"/>
<link href="https://fonts.googleapis.com/css?family=PT+Sans:400,700|Ubuntu:400,500,700italic|Droid+Sans:400,700" rel="stylesheet" type="text/css"/>
<link href="/xmlui/themes/Mirage2/styles/main.css" rel="stylesheet"/>
<link href="https://papyrus.bib.umontreal.ca:443/xmlui/description.xml" rel="search" title="DSpace" type="application/opensearchdescription+xml"/>
<script>
                //Clear default text of emty text areas on focus
                function tFocus(element)
                {
                if (element.value == ''){element.value='';}
                }
                //Clear default text of emty text areas on submit
                function tSubmit(form)
                {
                var defaultedElements = document.getElementsByTagName("textarea");
                for (var i=0; i != defaultedElements.length; i++){
                if (defaultedElements[i].value == ''){
                defaultedElements[i].value='';}}
                }
                //Disable pressing 'enter' key to submit a form (otherwise pressing 'enter' causes a submission to start over)
                function disableEnterKey(e)
                {
                var key;

                if(window.event)
                key = window.event.keyCode;     //Internet Explorer
                else
                key = e.which;     //Firefox and Netscape

                if(key == 13)  //if "Enter" pressed, then disable!
                return false;
                else
                return true;
                }
            </script><!--[if lt IE 9]>
                <script src="/xmlui/themes/Mirage2/vendor/html5shiv/dist/html5shiv.js"> </script>
                <script src="/xmlui/themes/Mirage2/vendor/respond/respond.min.js"> </script>
                <![endif]--><script src="/xmlui/themes/Mirage2/vendor/modernizr/modernizr.js"> </script><script src="https://www.bib.umontreal.ca/modele/urgence-udem/1.0.0/urgence-udem.js"></script>
<title>Auto-Encoders, Distributed Training and Information Representation in Deep Neural Networks</title>
<meta content="Dr8axyf94eWBJ8HQjNW4eKxTumAAPsNbvRwpJYMbgGs" name="google-site-verification"/>
<link href="http://purl.org/dc/terms/" rel="schema.DCTERMS">
<link href="http://purl.org/dc/elements/1.1/" rel="schema.DC">
<meta content="Bengio, Yoshua" name="DC.contributor">
<meta content="Alain, Guillaume" name="DC.creator">
<meta content="2019-11-20T20:54:05Z" name="DCTERMS.dateAccepted" scheme="DCTERMS.W3CDTF">
<meta content="NO_RESTRICTION" name="DCTERMS.available" scheme="DCTERMS.W3CDTF" xml:lang="fr">
<meta content="2019-11-20T20:54:05Z" name="DCTERMS.available" scheme="DCTERMS.W3CDTF">
<meta content="2019-06-19" name="DCTERMS.issued" scheme="DCTERMS.W3CDTF">
<meta content="2018-10" name="DC.date" scheme="DCTERMS.W3CDTF"/>
<meta content="http://hdl.handle.net/1866/22572" name="DC.identifier" scheme="DCTERMS.URI"/>
<meta content="Réseaux neuronaux" name="DC.subject" xml:lang="fr"/>
<meta content="Apprentissage profond" name="DC.subject" xml:lang="fr"/>
<meta content="Apprentissage de représentations" name="DC.subject" xml:lang="fr"/>
<meta content="Auto-encodeurs débruitants" name="DC.subject" xml:lang="fr"/>
<meta content="Optimisation Non-convexe" name="DC.subject" xml:lang="fr"/>
<meta content="Deep learning" name="DC.subject" xml:lang="fr"/>
<meta content="Neural networks" name="DC.subject" xml:lang="fr"/>
<meta content="Representation learning" name="DC.subject" xml:lang="fr"/>
<meta content="Denoising auto-encoders" name="DC.subject" xml:lang="fr"/>
<meta content="Non-convex optimization" name="DC.subject" xml:lang="fr"/>
<meta content="Applied Sciences - Artificial Intelligence / Sciences appliqués et technologie - Intelligence artificielle (UMI : 0800)" name="DC.subject" xml:lang="fr"/>
<meta content="Auto-Encoders, Distributed Training and Information Representation in Deep Neural Networks" name="DC.title" xml:lang="fr"/>
<meta content="Thèse ou mémoire / Thesis or Dissertation" name="DC.type"/>
<meta content="L'objectif de cette thèse est de présenter ma modeste contribution  à l'effort collectif de l'humanité pour comprendre l'intelligence et construire des machines intelligentes.
Ceci est une thèse par articles (cinq au total), tous représentant une entreprise personnelle dans laquelle j'ai consacré beaucoup d'énergie.

Les articles sont présentés en ordre chronologique, et ils touchent principalement à deux sujets : l'apprentissage de représentations et l'optimisation. Les articles des chapitres 3, 5 et 9
sont dans la première catégorie, et ceux des chapitres 7 et 11 sont dans la seconde catégorie.

Dans le premier article, nous partons de l'idée de modéliser la géométrie des données en entraînant un auto-encodeur débruitant qui reconstruit les données après qu'on les ait perturbées. Nous établissons un lien entre les auto-encodeurs contractifs et les auto-encodeurs débruitants. Notre contribution majeure consiste à démontrer mathématiquement une propriété intéressante qu'ont les solutions optimales aux auto-encodeurs débruitants lorsqu'ils sont définis à partir de bruit additif gaussien. Plus spécifiquement, nous démontrons qu'ils apprennent le score de la densité de probabilité. Nous présentons un ensemble de méthodes pratiques par lesquelles ce résultat nous permet de transformer un auto-encodeur en modèle génératif. Nous menons certaines expériences dans le but d'apprendre la géométrie locale des distributions de données.

Dans le second article, nous continuons dans la même ligne d'idées en construisant un modèle génératif basé sur l'apprentissage de distributions conditionnelles. Cet exercice se fait dans un cadre plus général et nous nous concentrons sur les propriétés de la chaine de Markov obtenu par échantillonnage de Gibbs. à l'aide d'une petite modification lors de la construction de la chaine de Markov, nous obtenons un modèle que l'on nomme &quot;Generative Stochastic Networks&quot;. Plusieurs copies de ce modèle peuvent se combiner pour créer une hiérarchie de représentations abstraites servant à mieux représenter la nature des données. Nous présentons des expériences sur l'ensemble de données MNIST et sur le remplissage d'images trouées.

Dans notre troisième article, nous présentons un nouveau paradigme pour l'optimisation parallèle. Nous proposons d'utiliser un ensemble de noeuds de calcul pour évaluer les coefficients nécessaires à faire de l'échantillonnage préférentiel sur les données d'entraînement. Cette idée ressemble beaucoup à l'apprentissage avec curriculum qui est une méthode dans laquelle l'ordre des données fournies au modèle est choisi avec beaucoup de soin dans le but de faciliter l'apprentissage.
Nous comparons les résultats expérimentaux observés à ceux anticipés en terme de réduction de variance sur les gradients.

Dans notre quatrième article, nous revenons au concept d'apprentissage de représentations et nous cherchons à savoir s'il serait possible de définir une notion utile de &quot;contenu en information&quot; dans le contexte de couches de réseaux neuronaux.
Ceci nous intéresse en particulier parce qu'il y a une sorte de paradoxe avec les réseaux profonds qui sont déterministes. Les couches les plus profondes ont des meilleures représentations que les premières couches, mais si l'on regarde strictement avec le point de vue de l'entropie (venant de la théorie de l'information) il est impossible qu'une couche plus profonde contienne plus d'information qu'une couche à l'entrée.
Nous développons une méthode d'entraînement de classifieur linéaire sur chaque couche du modèle étudié (dont les paramètres sont maintenant figés pendant l'étude). Nous appelons ces classifeurs des &quot;sondes linéaires de classification&quot;, et nous nous en servons pour mieux comprendre la dynamique particulière de l'entraînement d'un réseau profond.
Nous présentons des expériences menées sur des gros modèles (Inception v3 et ResNet-50), et nous découvrons une propriété étonnante : la performance de ces sondes augmente de manière monotone lorsque l'on descend dans les couches plus profondes.

Dans le cinquième article, nous retournons à l'optimisation, et nous étudions la courbure de l'espace de la fonction de perte. Nous regardons les vecteurs propres dominants de la matrice hessienne, et nous explorons les gains potentiels dans ces directions s'il était possible de faire un pas d'une longueur optimale.
Nous sommes principalement intéressés par les gains dans les directions associées aux valeurs propres négatives car celles-ci sont généralement ignorées par les méthodes populaire d'optimisation convexes. L'étude de la matrice hessienne demande des coûts énormes en calcul, et nous devons nous limiter à des expérience sur les données MNIST. Nous découvrons que des gains très importants peuvent être réalisés dans les directions de courbure négative, et que les longueurs de pas optimales sont beaucoup plus grandes que celles suggérées par la littérature existante." name="DCTERMS.abstract" xml:lang="fr"/>
<meta content="The goal of this thesis is to present a body of work that serves as my modest
contribution to humanity's
quest to understand intelligence and to implement intelligent systems.
This is a thesis by articles, containing five articles, not all of equal impact,
but all representing a very meaningful personal endeavor.

The articles are presented in chronological order, and they cluster
around two general topics : representation learning and optimization. Articles from chapters 3, 5, and 9
are in the former category, whereas articles from chapters 7 and 11 are in the latter.

In the first article, we start with the idea of manifold learning through training
a denoising auto-encoder to locally reconstruct data after perturbations.
We establish a connection between contractive auto-encoders and denoising auto-encoders.
More importantly, we prove mathematically a very interesting property from the
optimal solution to denoising auto-encoders with additive gaussian noise.
Namely, the fact that they learn exactly the score of the probability density function
of the training distribution. We present a collection of ways in which this
allows us to turn an auto-encoder into a generative model.
We provide experiments all related to the goal of local manifold learning.

In the second article, we continue with that idea of building a generative model
by learning conditional distributions. We do that in a more general setting
and we focus more on the properties of the Markov chain obtained by Gibbs sampling.
With a small modification in the construction of the Markov chain,
we obtain the more general &quot;Generative Stochastic Networks&quot;,
which we can then stack together into a structure that can represent more
accurately the different levels of abstraction of the data modeled.
We present experiments involving the generation of MNIST digits and image inpainting.

In the third article, we present a novel idea for distributed optimization.
Our proposal uses
a collection of worker nodes to compute the importance weights to be used
by one master node to perform Importance Sampling.
This paradigm has a lot in common with the idea of curriculum learning,
whereby the order of training examples is taken to have a significant impact on the
training performance.
We present results to compare the potential reduction in variance
for gradient estimates with the practical reduction in variance observed.

In the fourth article, we go back to the concept of representation learning
by asking whether there would be any measurable quantity in a neural network layer
that would correspond intuitively to its &quot;information contents&quot;.
This is particularly interesting because there is a kind of paradox in
deterministic neural networks : deeper layers encode better representations of the
input signal, but they carry less (or equal) information than the raw inputs (in terms of entropy).
By training a linear classifier on every layer in a neural network (with frozen parameters),
we are able to measure linearly separability of the representations at every layer.
We call these &quot;linear classifier probes&quot;, and we show how they
can be used to better understand the dynamics of training a neural network.
We present experiments with large models (Inception v3 and ResNet-50) and uncover
a surprizing property : linear separability increases in a strictly monotonic
relationship with the layer depth.

In the fifth article, we revisit optimization again, but now we study the negative
curvature of the loss function. We look at the most dominant eigenvalues and
eigenvectors of the Hessian matrix, and we explore the gains to be made
by modifying the model parameters along that direction with an optimal step size.
We are mainly interested in the potential gains for directions of negative curvature,
because those are ignored by the very popular convex optimization
methods used by the deep learning community.
Due to the large computational costs of anything dealing with
the Hessian matrix, we run a small model on MNIST. We find that large gains
can be made in directions of negative curvature, and that the optimal step sizes
involved are larger than the current literature would recommend." name="DCTERMS.abstract" xml:lang="fr"/>
<meta content="eng" name="DCTERMS.language" xml:lang="fr"/>
<meta content="Réseaux neuronaux; Apprentissage profond; Apprentissage de représentations; Auto-encodeurs débruitants; Optimisation Non-convexe; Deep learning; Neural networks; Representation learning; Denoising auto-encoders; Non-convex optimization; Applied Sciences - Artificial Intelligence / Sciences appliqués et technologie - Intelligence artificielle (UMI : 0800); Thèse ou mémoire / Thesis or Dissertation; Informatique" name="citation_keywords"/>
<meta content="Auto-Encoders, Distributed Training and Information Representation in Deep Neural Networks" name="citation_title"/>
<meta content="eng" name="citation_language"/>
<meta content="Alain, Guillaume" name="citation_author"/>
<meta content="https://papyrus.bib.umontreal.ca/xmlui/bitstream/1866/22572/2/Alain_Guillaume_2019_these.pdf" name="citation_pdf_url"/>
<meta content="2019-06-19" name="citation_date"/>
<meta content="https://papyrus.bib.umontreal.ca/xmlui/handle/1866/22572" name="citation_abstract_html_url"/>
<script type="text/x-mathjax-config">
                    MathJax.Hub.Config({
                      tex2jax: {
                        inlineMath: [['\\(','\\)']],
                        ignoreClass: "detail-field-data|detailtable|exception"
                      },
                      TeX: {
                        Macros: {
                          AA: '{\\mathring A}'
                        }
                      }
                    });
                </script><script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"> </script>
</meta></meta></meta></meta></meta></meta></link></link></head><body>
<header>
<div class="navbar navbar-default navbar-static-top" role="navigation">
<div class="container">
<div class="hidden-xs hidden-sm hidden-md" id="um-bandeau" role="banner">
<nav class="um-nav um-nav-hidden" role="navigation">
<span class="hidden">Liens externes</span>
<ul>
<li>
<a href="https://www.umontreal.ca/#udemwww-search-personne">Directories</a>
</li>
<li>
<a href="http://www.umontreal.ca/repertoires/facultes.html">Faculties</a>
</li>
<li>
<a href="http://www.bib.umontreal.ca/">Libraries</a>
</li>
<li>
<a href="http://plancampus.umontreal.ca/">Campus maps</a>
</li>
<li>
<a href="http://www.umontreal.ca/index/az.html">Sites A to Z</a>
</li>
<li>
<a>My UdeM</a>
<ul>
<li>
<a href="https://monudem.umontreal.ca/">My UdeM Portal</a>
</li>
<li>
<a href="https://outlook.umontreal.ca">My email</a>
</li>
<li>
<a href="https://studium.umontreal.ca/">StudiUM</a>
</li>
</ul>
</li>
</ul>
</nav>
<form action="https://google.com/cse" class="um-recherche" id="um-recherche" role="search">
<input name="cx" type="hidden" value="011926736769028447783:qlpu3so2kqq"/><input name="ie" type="hidden" value="ISO-8859-1"/><label class="hidden" for="um-boite-recherche">Search in : </label><span class="um-boite-bouton"><input class="um-boite" id="um-boite-recherche" maxlength="255" name="q" placeholder="UdeM" title="Type your search text" type="text" value=""/><input alt="Search in : " class="um-bouton" src="/xmlui/themes/Mirage2/images/bib-umontreal/loupe.gif" type="image"/></span>
</form>
</div>
<div class="hidden-xs hidden-sm visible-md visible-lg" id="papyrus-deco">
<img alt="Dessin du pavillon Roger Gaudry/Sketch of Roger Gaudry Building" border="0" height="89px" src="/xmlui/themes/Mirage2/images/UdeM.gif" title="Dessin du pavillon Roger Gaudry/Sketch of Roger Gaudry Building" width="193px"/></div>
<div class="navbar-header">
<button class="navbar-toggle" data-toggle="offcanvas" type="button"><span class="sr-only">Toggle navigation</span><span class="icon-bar"></span><span class="icon-bar"></span><span class="icon-bar"></span></button><a class="navbar-brand hidden-xs hidden-sm visible-md visible-lg um-logo-md-lg" href="http://www.umontreal.ca/english/index.html"><img alt="University Home page" src="/xmlui/themes/Mirage2/images/logo-UdeM.svg" title="Back to University Home page"/></a><a class="navbar-brand hidden-xs visible-sm hidden-md hidden-lg um-logo-sm" href="http://www.umontreal.ca/english/index.html"><img alt="University Home page" src="/xmlui/themes/Mirage2/images/logo-UdeM.svg" title="Back to University Home page"/></a><a class="navbar-brand visible-xs hidden-sm hidden-md hidden-lg um-logo-xs" href="http://www.umontreal.ca/english/index.html"><img alt="University Home page" src="/xmlui/themes/Mirage2/images/logo-UdeM.svg" title="Back to University Home page"/></a>
<div class="navbar-brand separateur visible-xs hidden-sm hidden-md hidden-lg um-sep-site-xs"></div>
<div class="navbar-brand separateur hidden-xs visible-sm hidden-md hidden-lg um-sep-site-sm"></div>
<div class="navbar-brand separateur visible-md visible-lg hidden-xs hidden-sm um-sep-site-md-lg"></div>
<div class="navbar-brand visible-md visible-lg hidden-xs hidden-sm um-titre-site-md-lg">
<span class="papyrus-signature">Papyrus</span> :
                                Institutional Repository</div>
<div class="navbar-brand hidden-xs visible-sm hidden-md hidden-lg um-titre-site-sm">
<span class="papyrus-signature">Papyrus</span>
<br/>Institutional Repository</div>
<div class="navbar-brand visible-xs hidden-sm hidden-md hidden-lg um-titre-site-xs">
<span class="papyrus-signature">Papyrus</span>
</div>
<div class="navbar-header pull-right visible-xs hidden-sm hidden-md hidden-lg">
<ul class="nav nav-pills pull-left">
<li class="dropdown" id="ds-language-selection-xs">
<button class="dropdown-toggle navbar-toggle navbar-link" data-toggle="dropdown" href="#" id="language-dropdown-toggle-xs" role="button"><b aria-hidden="true" class="visible-xs glyphicon glyphicon-globe"></b></button>
<ul aria-labelledby="language-dropdown-toggle-xs" class="dropdown-menu pull-right" data-no-collapse="true" role="menu">
<li role="presentation">
<a href="https://papyrus.bib.umontreal.ca:443/xmlui/handle/1866/22572?locale-attribute=fr&amp;show=full">français</a>
</li>
<li class="disabled" role="presentation">
<a href="https://papyrus.bib.umontreal.ca:443/xmlui/handle/1866/22572?locale-attribute=en&amp;show=full">English</a>
</li>
</ul>
</li>
<li>
<form action="/xmlui/login" method="get" style="display: inline">
<button class="navbar-toggle navbar-link"><b aria-hidden="true" class="visible-xs glyphicon glyphicon-user"></b></button>
</form>
</li>
</ul>
</div>
</div>
<div class="navbar-header pull-right hidden-xs">
<div class="nav-language-and-login-lg hidden-xs hidden-sm hidden-md">
<ul class="nav navbar-nav pull-right">
<li class="dropdown" id="ds-language-selection">
<a class="dropdown-toggle" data-toggle="dropdown" href="#" id="language-dropdown-toggle" role="button"><span class="hidden-xs">English <b class="caret"></b></span></a>
<ul aria-labelledby="language-dropdown-toggle" class="dropdown-menu pull-right" data-no-collapse="true" role="menu">
<li role="presentation">
<a href="https://papyrus.bib.umontreal.ca:443/xmlui/handle/1866/22572?locale-attribute=fr&amp;show=full">français</a>
</li>
<li class="disabled" role="presentation">
<a href="https://papyrus.bib.umontreal.ca:443/xmlui/handle/1866/22572?locale-attribute=en&amp;show=full">English</a>
</li>
</ul>
</li>
</ul>
<ul class="nav navbar-nav pull-right">
<li>
<a href="/xmlui/login"><span class="hidden-xs">Login</span></a>
</li>
</ul>
</div>
<div class="hidden-lg">
<ul class="nav navbar-nav pull-right">
<li class="dropdown" id="ds-language-selection">
<a class="dropdown-toggle" data-toggle="dropdown" href="#" id="language-dropdown-toggle" role="button"><span class="hidden-xs">English <b class="caret"></b></span></a>
<ul aria-labelledby="language-dropdown-toggle" class="dropdown-menu pull-right" data-no-collapse="true" role="menu">
<li role="presentation">
<a href="https://papyrus.bib.umontreal.ca:443/xmlui/handle/1866/22572?locale-attribute=fr&amp;show=full">français</a>
</li>
<li class="disabled" role="presentation">
<a href="https://papyrus.bib.umontreal.ca:443/xmlui/handle/1866/22572?locale-attribute=en&amp;show=full">English</a>
</li>
</ul>
</li>
</ul>
<ul class="nav navbar-nav pull-right">
<li>
<a href="/xmlui/login"><span class="hidden-xs">Login</span></a>
</li>
</ul>
</div>
<button class="navbar-toggle visible-sm" data-toggle="offcanvas" type="button"><span class="sr-only">Toggle navigation</span><span class="icon-bar"></span><span class="icon-bar"></span><span class="icon-bar"></span></button>
</div>
</div>
</div>
</header>
<div class="trail-wrapper hidden-print">
<div class="container">
<div class="row">
<div class="col-xs-12">
<div class="breadcrumb dropdown visible-xs">
<a class="dropdown-toggle" data-toggle="dropdown" href="#" id="trail-dropdown-toggle" role="button">View Item <b class="caret"></b></a>
<ul aria-labelledby="trail-dropdown-toggle" class="dropdown-menu" role="menu">
<li role="presentation">
<a href="/xmlui/" role="menuitem"><i aria-hidden="true" class="glyphicon glyphicon-home"></i>  Home</a>
</li>
<li role="presentation">
<a href="/xmlui/handle/1866/3010" role="menuitem">Faculté des arts et des sciences</a>
</li>
<li role="presentation">
<a href="/xmlui/handle/1866/2958" role="menuitem">Faculté des arts et des sciences – Département d'informatique et de recherche opérationnelle</a>
</li>
<li role="presentation">
<a href="/xmlui/handle/1866/3001" role="menuitem">Faculté des arts et des sciences – Département d'informatique et de recherche opérationnelle - Thèses et mémoires</a>
</li>
<li class="disabled" role="presentation">
<a href="#" role="menuitem">View Item</a>
</li>
</ul>
</div>
<ul class="breadcrumb hidden-xs">
<li>
<i aria-hidden="true" class="glyphicon glyphicon-home"></i>  <a href="/xmlui/">Home</a>
</li>
<li>
<a href="/xmlui/handle/1866/3010">Faculté des arts et des sciences</a>
</li>
<li>
<a href="/xmlui/handle/1866/2958">Faculté des arts et des sciences – Département d'informatique et de recherche opérationnelle</a>
</li>
<li>
<a href="/xmlui/handle/1866/3001">Faculté des arts et des sciences – Département d'informatique et de recherche opérationnelle - Thèses et mémoires</a>
</li>
<li class="active">View Item</li>
</ul>
</div>
</div>
</div>
</div>
<div class="hidden" id="no-js-warning-wrapper">
<div id="no-js-warning">
<div class="notice failure">JavaScript is disabled for your browser. Some features of this site may not work without it.</div>
</div>
</div>
<div class="container" id="main-container">
<div class="row row-offcanvas row-offcanvas-left">
<div class="horizontal-slider clearfix">
<div class="col-xs-6 col-sm-3 sidebar-offcanvas" id="sidebar" role="navigation">
<div class="word-break hidden-print" id="ds-options">
<div class="ds-option-set" id="ds-search-option">
<form action="/xmlui/discover" class="" id="ds-search-form" method="post">
<fieldset>
<div class="input-group">
<input class="ds-text-field form-control" name="query" placeholder="Search" type="text"/><span class="input-group-btn"><button class="ds-button-field btn" title="Go"><span aria-hidden="true" class="glyphicon glyphicon-search"></span></button></span>
</div>
<div class="radio">
<label><input checked="" id="ds-search-form-scope-all" name="scope" type="radio" value=""/>Search Papyrus</label>
</div>
<div class="radio">
<label><input id="ds-search-form-scope-container" name="scope" type="radio" value="1866/3001"/>Search this Collection</label>
</div>
</fieldset>
</form>
</div>
<h2 class="ds-option-set-head h6">My Account</h2>
<div class="list-group" id="aspect_viewArtifacts_Navigation_list_account">
<div class="list-group-item ds-option details_Papyrus" id="aspect_eperson_Navigation_item_details_Papyrus">To submit an item or subscribe to email alerts.</div>
<div class="list-group-item ds-option">
<span class="bold"><a href="/xmlui/login">Login</a></span>
</div>
<a class="list-group-item ds-option" href="/xmlui/register">New user?</a>
</div>
<h2 class="ds-option-set-head h6">Browse</h2>
<div class="list-group" id="aspect_viewArtifacts_Navigation_list_browse">
<a class="list-group-item active"><span class="h5 list-group-item-heading h5">All of Papyrus</span></a><a class="list-group-item ds-option" href="/xmlui/community-list">Communities and Collections</a><a class="list-group-item ds-option" href="/xmlui/browse?type=title">Titles</a><a class="list-group-item ds-option" href="/xmlui/browse?type=dateissued">Issue Dates</a><a class="list-group-item ds-option" href="/xmlui/browse?type=author">Authors</a><a class="list-group-item ds-option" href="/xmlui/browse?type=advisor">Advisors</a><a class="list-group-item ds-option" href="/xmlui/browse?type=subject">Subjects</a><a class="list-group-item ds-option" href="/xmlui/browse?type=discipline">Disciplines</a><a class="list-group-item ds-option" href="/xmlui/browse?type=affiliation">Affiliation</a><a class="list-group-item ds-option" href="/xmlui/browse?type=titleindex">Titles index</a><a class="list-group-item active"><span class="h5 list-group-item-heading h5">This Collection</span></a><a class="list-group-item ds-option" href="/xmlui/handle/1866/3001/browse?type=title">Titles</a><a class="list-group-item ds-option" href="/xmlui/handle/1866/3001/browse?type=dateissued">Issue Dates</a><a class="list-group-item ds-option" href="/xmlui/handle/1866/3001/browse?type=author">Authors</a><a class="list-group-item ds-option" href="/xmlui/handle/1866/3001/browse?type=advisor">Advisors</a><a class="list-group-item ds-option" href="/xmlui/handle/1866/3001/browse?type=subject">Subjects</a><a class="list-group-item ds-option" href="/xmlui/handle/1866/3001/browse?type=discipline">Disciplines</a><a class="list-group-item ds-option" href="/xmlui/handle/1866/3001/browse?type=affiliation">Affiliation</a><a class="list-group-item ds-option" href="/xmlui/handle/1866/3001/browse?type=titleindex">Titles index</a>
</div>
<div class="list-group" id="aspect_viewArtifacts_Navigation_list_context"></div>
<div class="list-group" id="aspect_viewArtifacts_Navigation_list_administrative"></div>
<div class="list-group" id="aspect_discovery_Navigation_list_discovery"></div>
<h2 class="ds-option-set-head h6">Statistics</h2>
<div class="list-group" id="aspect_statistics_Navigation_list_statistics">
<a class="list-group-item ds-option" href="/xmlui/handle/1866/22572/statistics">View Usage Statistics</a>
</div>
</div>
</div>
<div class="col-xs-12 col-sm-12 col-md-9 main-content">
<div>
<div class="ds-static-div primary" id="aspect_artifactbrowser_ItemViewer_div_item-view">
<p class="ds-paragraph item-view-toggle item-view-toggle-top">
<span class="item-view-toggle"><a href="/xmlui/handle/1866/22572">Show item record</a></span>
</p>
<!-- External Metadata URL: cocoon://metadata/handle/1866/22572/mets.xml-->
<h2 class="page-header first-page-header">Auto-Encoders, Distributed Training and Information Representation in Deep Neural Networks</h2>
<div class="ds-table-responsive">
<table class="ds-includeSet-table detailtable table table-striped table-hover">
<tr class="ds-table-row odd">
<td class="label-cell">dc.contributor.advisor</td><td class="word-break">Bengio, Yoshua</td><td></td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.contributor.author</td><td class="word-break">Alain, Guillaume</td><td></td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.date.accessioned</td><td class="word-break">2019-11-20T20:54:05Z</td><td></td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.date.available</td><td class="word-break">NO_RESTRICTION</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.date.available</td><td class="word-break">2019-11-20T20:54:05Z</td><td></td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.date.issued</td><td class="word-break">2019-06-19</td><td></td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.date.submitted</td><td class="word-break">2018-10</td><td></td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.identifier.uri</td><td class="word-break">http://hdl.handle.net/1866/22572</td><td></td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject</td><td class="word-break">Réseaux neuronaux</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">Apprentissage profond</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject</td><td class="word-break">Apprentissage de représentations</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">Auto-encodeurs débruitants</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject</td><td class="word-break">Optimisation Non-convexe</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">Deep learning</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject</td><td class="word-break">Neural networks</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">Representation learning</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject</td><td class="word-break">Denoising auto-encoders</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">Non-convex optimization</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject.other</td><td class="word-break">Applied Sciences - Artificial Intelligence / Sciences appliqués et technologie - Intelligence artificielle (UMI : 0800)</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.title</td><td class="word-break">Auto-Encoders, Distributed Training and Information Representation in Deep Neural Networks</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.type</td><td class="word-break">Thèse ou mémoire / Thesis or Dissertation</td><td></td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">etd.degree.discipline</td><td class="word-break">Informatique</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">etd.degree.grantor</td><td class="word-break">Université de Montréal</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">etd.degree.level</td><td class="word-break">Doctorat / Doctoral</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">etd.degree.name</td><td class="word-break">Ph. D.</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dcterms.abstract</td><td class="word-break">L'objectif de cette thèse est de présenter ma modeste contribution  à l'effort collectif de l'humanité pour comprendre l'intelligence et construire des machines intelligentes.
Ceci est une thèse par articles (cinq au total), tous représentant une entreprise personnelle dans laquelle j'ai consacré beaucoup d'énergie.

Les articles sont présentés en ordre chronologique, et ils touchent principalement à deux sujets : l'apprentissage de représentations et l'optimisation. Les articles des chapitres 3, 5 et 9
sont dans la première catégorie, et ceux des chapitres 7 et 11 sont dans la seconde catégorie.

Dans le premier article, nous partons de l'idée de modéliser la géométrie des données en entraînant un auto-encodeur débruitant qui reconstruit les données après qu'on les ait perturbées. Nous établissons un lien entre les auto-encodeurs contractifs et les auto-encodeurs débruitants. Notre contribution majeure consiste à démontrer mathématiquement une propriété intéressante qu'ont les solutions optimales aux auto-encodeurs débruitants lorsqu'ils sont définis à partir de bruit additif gaussien. Plus spécifiquement, nous démontrons qu'ils apprennent le score de la densité de probabilité. Nous présentons un ensemble de méthodes pratiques par lesquelles ce résultat nous permet de transformer un auto-encodeur en modèle génératif. Nous menons certaines expériences dans le but d'apprendre la géométrie locale des distributions de données.

Dans le second article, nous continuons dans la même ligne d'idées en construisant un modèle génératif basé sur l'apprentissage de distributions conditionnelles. Cet exercice se fait dans un cadre plus général et nous nous concentrons sur les propriétés de la chaine de Markov obtenu par échantillonnage de Gibbs. à l'aide d'une petite modification lors de la construction de la chaine de Markov, nous obtenons un modèle que l'on nomme "Generative Stochastic Networks". Plusieurs copies de ce modèle peuvent se combiner pour créer une hiérarchie de représentations abstraites servant à mieux représenter la nature des données. Nous présentons des expériences sur l'ensemble de données MNIST et sur le remplissage d'images trouées.

Dans notre troisième article, nous présentons un nouveau paradigme pour l'optimisation parallèle. Nous proposons d'utiliser un ensemble de noeuds de calcul pour évaluer les coefficients nécessaires à faire de l'échantillonnage préférentiel sur les données d'entraînement. Cette idée ressemble beaucoup à l'apprentissage avec curriculum qui est une méthode dans laquelle l'ordre des données fournies au modèle est choisi avec beaucoup de soin dans le but de faciliter l'apprentissage.
Nous comparons les résultats expérimentaux observés à ceux anticipés en terme de réduction de variance sur les gradients.

Dans notre quatrième article, nous revenons au concept d'apprentissage de représentations et nous cherchons à savoir s'il serait possible de définir une notion utile de "contenu en information" dans le contexte de couches de réseaux neuronaux.
Ceci nous intéresse en particulier parce qu'il y a une sorte de paradoxe avec les réseaux profonds qui sont déterministes. Les couches les plus profondes ont des meilleures représentations que les premières couches, mais si l'on regarde strictement avec le point de vue de l'entropie (venant de la théorie de l'information) il est impossible qu'une couche plus profonde contienne plus d'information qu'une couche à l'entrée.
Nous développons une méthode d'entraînement de classifieur linéaire sur chaque couche du modèle étudié (dont les paramètres sont maintenant figés pendant l'étude). Nous appelons ces classifeurs des "sondes linéaires de classification", et nous nous en servons pour mieux comprendre la dynamique particulière de l'entraînement d'un réseau profond.
Nous présentons des expériences menées sur des gros modèles (Inception v3 et ResNet-50), et nous découvrons une propriété étonnante : la performance de ces sondes augmente de manière monotone lorsque l'on descend dans les couches plus profondes.

Dans le cinquième article, nous retournons à l'optimisation, et nous étudions la courbure de l'espace de la fonction de perte. Nous regardons les vecteurs propres dominants de la matrice hessienne, et nous explorons les gains potentiels dans ces directions s'il était possible de faire un pas d'une longueur optimale.
Nous sommes principalement intéressés par les gains dans les directions associées aux valeurs propres négatives car celles-ci sont généralement ignorées par les méthodes populaire d'optimisation convexes. L'étude de la matrice hessienne demande des coûts énormes en calcul, et nous devons nous limiter à des expérience sur les données MNIST. Nous découvrons que des gains très importants peuvent être réalisés dans les directions de courbure négative, et que les longueurs de pas optimales sont beaucoup plus grandes que celles suggérées par la littérature existante.</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dcterms.abstract</td><td class="word-break">The goal of this thesis is to present a body of work that serves as my modest
contribution to humanity's
quest to understand intelligence and to implement intelligent systems.
This is a thesis by articles, containing five articles, not all of equal impact,
but all representing a very meaningful personal endeavor.

The articles are presented in chronological order, and they cluster
around two general topics : representation learning and optimization. Articles from chapters 3, 5, and 9
are in the former category, whereas articles from chapters 7 and 11 are in the latter.

In the first article, we start with the idea of manifold learning through training
a denoising auto-encoder to locally reconstruct data after perturbations.
We establish a connection between contractive auto-encoders and denoising auto-encoders.
More importantly, we prove mathematically a very interesting property from the
optimal solution to denoising auto-encoders with additive gaussian noise.
Namely, the fact that they learn exactly the score of the probability density function
of the training distribution. We present a collection of ways in which this
allows us to turn an auto-encoder into a generative model.
We provide experiments all related to the goal of local manifold learning.

In the second article, we continue with that idea of building a generative model
by learning conditional distributions. We do that in a more general setting
and we focus more on the properties of the Markov chain obtained by Gibbs sampling.
With a small modification in the construction of the Markov chain,
we obtain the more general "Generative Stochastic Networks",
which we can then stack together into a structure that can represent more
accurately the different levels of abstraction of the data modeled.
We present experiments involving the generation of MNIST digits and image inpainting.

In the third article, we present a novel idea for distributed optimization.
Our proposal uses
a collection of worker nodes to compute the importance weights to be used
by one master node to perform Importance Sampling.
This paradigm has a lot in common with the idea of curriculum learning,
whereby the order of training examples is taken to have a significant impact on the
training performance.
We present results to compare the potential reduction in variance
for gradient estimates with the practical reduction in variance observed.

In the fourth article, we go back to the concept of representation learning
by asking whether there would be any measurable quantity in a neural network layer
that would correspond intuitively to its "information contents".
This is particularly interesting because there is a kind of paradox in
deterministic neural networks : deeper layers encode better representations of the
input signal, but they carry less (or equal) information than the raw inputs (in terms of entropy).
By training a linear classifier on every layer in a neural network (with frozen parameters),
we are able to measure linearly separability of the representations at every layer.
We call these "linear classifier probes", and we show how they
can be used to better understand the dynamics of training a neural network.
We present experiments with large models (Inception v3 and ResNet-50) and uncover
a surprizing property : linear separability increases in a strictly monotonic
relationship with the layer depth.

In the fifth article, we revisit optimization again, but now we study the negative
curvature of the loss function. We look at the most dominant eigenvalues and
eigenvectors of the Hessian matrix, and we explore the gains to be made
by modifying the model parameters along that direction with an optimal step size.
We are mainly interested in the potential gains for directions of negative curvature,
because those are ignored by the very popular convex optimization
methods used by the deep learning community.
Due to the large computational costs of anything dealing with
the Hessian matrix, we run a small model on MNIST. We find that large gains
can be made in directions of negative curvature, and that the optimal step sizes
involved are larger than the current literature would recommend.</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dcterms.language</td><td class="word-break">eng</td><td>fr</td>
</tr>
</table>
</div>
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc&amp;rft_id=http%3A%2F%2Fhdl.handle.net%2F1866%2F22572&amp;rfr_id=info%3Asid%2Fdspace.org%3Arepository&amp;rft.degree=Informatique&amp;rft.degree=Universit%C3%A9+de+Montr%C3%A9al&amp;rft.degree=Doctorat+%2F+Doctoral&amp;rft.degree=Ph.+D."> ﻿ 
        </span>
<h3>Files in this item</h3>
<div class="file-list">
<div class="file-wrapper row">
<div class="col-xs-6 col-sm-3">
<div class="thumbnail-wrapper">
<a class="image-link" href="/xmlui/bitstream/handle/1866/22572/Alain_Guillaume_2019_these.pdf?sequence=2&amp;isAllowed=y"><img alt="Thumbnail" class="thumbnail-papyrus" src="/xmlui/bitstream/handle/1866/22572/Alain_Guillaume_2019_these.pdf.jpg?sequence=4&amp;isAllowed=y"/></a>
<div class="imageoverlay">
<img height="49" src="/xmlui/themes/Mirage2/images/mimes/mime_icone_pdf.png" style="height: 49px;" width="44"/></div>
</div>
</div>
<div class="col-xs-6 col-sm-7">
<dl class="file-metadata dl-horizontal">
<dt>Name:</dt>
<dd class="word-break" title="Alain_Guillaume_2019_these.pdf">
<a href="/xmlui/bitstream/handle/1866/22572/Alain_Guillaume_2019_these.pdf?sequence=2&amp;isAllowed=y">Alain_Guillaume_2019_these.pdf</a>
</dd>
<dt>Size:</dt>
<dd class="word-break">13.10Mb</dd>
<dt>Format:</dt>
<dd class="word-break">PDF</dd>
<dt>Description:</dt>
<dd class="word-break" title="Thèse">Thèse</dd>
</dl>
</div>
</div>
</div>
<h3 class="ds-list-head">This item appears in the following Collection(s)</h3>
<ul class="ds-referenceSet-list">
<!-- External Metadata URL: cocoon://metadata/handle/1866/2621/mets.xml-->
<li>
<a href="/xmlui/handle/1866/2621">Thèses et mémoires électroniques de l’Université de Montréal</a> [18270]<br/>
</li>
<!-- External Metadata URL: cocoon://metadata/handle/1866/3001/mets.xml-->
<li>
<a href="/xmlui/handle/1866/3001">Faculté des arts et des sciences – Département d'informatique et de recherche opérationnelle - Thèses et mémoires</a> [795]<br/>
</li>
</ul>
<p class="ds-paragraph item-view-toggle item-view-toggle-bottom">
<span class="item-view-toggle"><a href="/xmlui/handle/1866/22572">Show item record</a></span>
</p>
</div>
</div>
<div class="visible-xs visible-sm">
<footer>
<div class="row">
<hr/>
<div class="col-xs-7 col-sm-8">
<div>
<a href="http://www.dspace.org/" target="_blank">DSpace software</a>
                        [version 5.8 XMLUI],
                        copyright © 2002-2015  <a href="http://www.duraspace.org/" target="_blank">DuraSpace</a>
</div>
<div class="hidden-print">
<a href="/xmlui/contact">Contact Us</a> | <a href="/xmlui/feedback">Send Feedback</a>
</div>
</div>
<div class="col-xs-5 col-sm-4 hidden-print">
<div class="pull-right">
<script type="text/javascript"> 
										      (function(d, t) { 
										        var s = d.createElement(t), options = {'domain':'papyrus.bib.umontreal.ca','style': '16','container':'entrust-net-seal'}; 
										        s.src = 'https://seal.entrust.net/sealv2.js'; 
										        s.async = true; 
										        var scr = d.getElementsByTagName(t)[0], par = scr.parentNode; par.insertBefore(s, scr); 
										        s.onload = s.onreadystatechange = function() { 
										        var rs = this.readyState; if (rs) if (rs != 'complete') if (rs != 'loaded') return; 
										        try{goEntrust(options)} catch (e) {} }; 
										        })(document, 'script'); 
										</script>
<div id="entrust-net-seal">
<a href="https://www.entrust.com/ssl-certificates/">Certificat SSL / SSL Certificate</a>
</div>
</div>
</div>
</div>
<div class="row bib-footer hidden-print">
<div class="col-xs-12 col-sm-12 col-md-4">
<a class="footerEXLlink" href="http://www.bib.umontreal.ca"><img alt="les bibliothèques/UdeM" src="/xmlui/themes/Mirage2/images/propulse-par.png"/></a>
</div>
<div class="hidden-xs col-sm-12 col-md-8">
<nav>
<ul>
<li>
<a href="https://www.urgence.umontreal.ca/">Emergency</a>
</li>
<li>
<a href="http://www.carrieres.umontreal.ca/">Careers</a>
</li>
<li>
<a href="https://outlook.umontreal.ca/">My email</a>
</li>
<li>
<a href="https://studium.umontreal.ca/">StudiUM</a>
</li>
<li>
<a href="http://itunesu.umontreal.ca/">iTunes U</a>
</li>
<li>
<a href="http://www.bib.umontreal.ca/a-propos/nous-ecrire.htm">Contact us</a>
</li>
<li>
<a href="https://www.facebook.com/bibUdeM"><img alt="Facebook" src="/xmlui/themes/Mirage2/images/bib-umontreal/logo-Facebook.png"/></a>
</li>
<li>
<a href="https://www.youtube.com/user/BibliothequesUdeM"><img alt="YouTube" src="/xmlui/themes/Mirage2/images/bib-umontreal/logo-YouTube.png"/></a>
</li>
<li>
<a href="https://twitter.com/bibUdeM"><img alt="Twitter" src="/xmlui/themes/Mirage2/images/bib-umontreal/logo-Twitter.png"/></a>
</li>
<li>
<a href="https://www.nouvelles.umontreal.ca/frontpage/rss.html"><img alt="University RSS" src="/xmlui/themes/Mirage2/images/bib-umontreal/icone-syndication-14x14.png"/></a>
</li>
</ul>
</nav>
</div>
</div>
<a class="hidden" href="/xmlui/htmlmap"> </a>
<p> </p>
</footer>
</div>
</div>
</div>
</div>
<div class="hidden-xs hidden-sm">
<footer>
<div class="row">
<hr/>
<div class="col-xs-7 col-sm-8">
<div>
<a href="http://www.dspace.org/" target="_blank">DSpace software</a>
                        [version 5.8 XMLUI],
                        copyright © 2002-2015  <a href="http://www.duraspace.org/" target="_blank">DuraSpace</a>
</div>
<div class="hidden-print">
<a href="/xmlui/contact">Contact Us</a> | <a href="/xmlui/feedback">Send Feedback</a>
</div>
</div>
<div class="col-xs-5 col-sm-4 hidden-print">
<div class="pull-right">
<script type="text/javascript"> 
										      (function(d, t) { 
										        var s = d.createElement(t), options = {'domain':'papyrus.bib.umontreal.ca','style': '16','container':'entrust-net-seal'}; 
										        s.src = 'https://seal.entrust.net/sealv2.js'; 
										        s.async = true; 
										        var scr = d.getElementsByTagName(t)[0], par = scr.parentNode; par.insertBefore(s, scr); 
										        s.onload = s.onreadystatechange = function() { 
										        var rs = this.readyState; if (rs) if (rs != 'complete') if (rs != 'loaded') return; 
										        try{goEntrust(options)} catch (e) {} }; 
										        })(document, 'script'); 
										</script>
<div id="entrust-net-seal">
<a href="https://www.entrust.com/ssl-certificates/">Certificat SSL / SSL Certificate</a>
</div>
</div>
</div>
</div>
<div class="row bib-footer hidden-print">
<div class="col-xs-12 col-sm-12 col-md-4">
<a class="footerEXLlink" href="http://www.bib.umontreal.ca"><img alt="les bibliothèques/UdeM" src="/xmlui/themes/Mirage2/images/propulse-par.png"/></a>
</div>
<div class="hidden-xs col-sm-12 col-md-8">
<nav>
<ul>
<li>
<a href="https://www.urgence.umontreal.ca/">Emergency</a>
</li>
<li>
<a href="http://www.carrieres.umontreal.ca/">Careers</a>
</li>
<li>
<a href="https://outlook.umontreal.ca/">My email</a>
</li>
<li>
<a href="https://studium.umontreal.ca/">StudiUM</a>
</li>
<li>
<a href="http://itunesu.umontreal.ca/">iTunes U</a>
</li>
<li>
<a href="http://www.bib.umontreal.ca/a-propos/nous-ecrire.htm">Contact us</a>
</li>
<li>
<a href="https://www.facebook.com/bibUdeM"><img alt="Facebook" src="/xmlui/themes/Mirage2/images/bib-umontreal/logo-Facebook.png"/></a>
</li>
<li>
<a href="https://www.youtube.com/user/BibliothequesUdeM"><img alt="YouTube" src="/xmlui/themes/Mirage2/images/bib-umontreal/logo-YouTube.png"/></a>
</li>
<li>
<a href="https://twitter.com/bibUdeM"><img alt="Twitter" src="/xmlui/themes/Mirage2/images/bib-umontreal/logo-Twitter.png"/></a>
</li>
<li>
<a href="https://www.nouvelles.umontreal.ca/frontpage/rss.html"><img alt="University RSS" src="/xmlui/themes/Mirage2/images/bib-umontreal/icone-syndication-14x14.png"/></a>
</li>
</ul>
</nav>
</div>
</div>
<a class="hidden" href="/xmlui/htmlmap"> </a>
<p> </p>
</footer>
</div>
</div>
<script src="https://www.google.com/jsapi"> </script><script>if(!window.DSpace){window.DSpace={};}window.DSpace.context_path='/xmlui';window.DSpace.theme_path='/xmlui/themes/Mirage2/';</script><script src="/xmlui/themes/Mirage2/scripts/theme.js"> </script><script>
                  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

                  ga('create', 'UA-305727-1', 'papyrus.bib.umontreal.ca');
                  ga('send', 'pageview');
           </script><script>         
             var details_Papyrus =  $("#aspect_viewArtifacts_Navigation_list_account .details_Papyrus").text();
             $("#aspect_viewArtifacts_Navigation_list_account a[href='/xmlui/login']").attr("title",details_Papyrus);
        </script>
</body></html>
