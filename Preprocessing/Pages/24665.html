<!DOCTYPE html>

<!--[if lt IE 7]> <html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if IE 7]>    <html class="no-js lt-ie9 lt-ie8" lang="en"> <![endif]-->
<!--[if IE 8]>    <html class="no-js lt-ie9" lang="en"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="/xmlui/themes/Mirage2/images/favicon.ico" rel="shortcut icon"/>
<link href="/xmlui/themes/Mirage2/images/apple-touch-icon.png" rel="apple-touch-icon"/>
<meta content="DSpace 5.8" name="Generator"/>
<link href="https://fonts.googleapis.com/css?family=PT+Sans:400,700|Ubuntu:400,500,700italic|Droid+Sans:400,700" rel="stylesheet" type="text/css"/>
<link href="/xmlui/themes/Mirage2/styles/main.css" rel="stylesheet"/>
<link href="https://papyrus.bib.umontreal.ca:443/xmlui/description.xml" rel="search" title="DSpace" type="application/opensearchdescription+xml"/>
<script>
                //Clear default text of emty text areas on focus
                function tFocus(element)
                {
                if (element.value == ''){element.value='';}
                }
                //Clear default text of emty text areas on submit
                function tSubmit(form)
                {
                var defaultedElements = document.getElementsByTagName("textarea");
                for (var i=0; i != defaultedElements.length; i++){
                if (defaultedElements[i].value == ''){
                defaultedElements[i].value='';}}
                }
                //Disable pressing 'enter' key to submit a form (otherwise pressing 'enter' causes a submission to start over)
                function disableEnterKey(e)
                {
                var key;

                if(window.event)
                key = window.event.keyCode;     //Internet Explorer
                else
                key = e.which;     //Firefox and Netscape

                if(key == 13)  //if "Enter" pressed, then disable!
                return false;
                else
                return true;
                }
            </script><!--[if lt IE 9]>
                <script src="/xmlui/themes/Mirage2/vendor/html5shiv/dist/html5shiv.js"> </script>
                <script src="/xmlui/themes/Mirage2/vendor/respond/respond.min.js"> </script>
                <![endif]--><script src="/xmlui/themes/Mirage2/vendor/modernizr/modernizr.js"> </script><script src="https://www.bib.umontreal.ca/modele/urgence-udem/1.0.0/urgence-udem.js"></script>
<title>Characterizing and comparing acoustic representations in convolutional neural networks and the human auditory system</title>
<meta content="Dr8axyf94eWBJ8HQjNW4eKxTumAAPsNbvRwpJYMbgGs" name="google-site-verification"/>
<link href="http://purl.org/dc/terms/" rel="schema.DCTERMS">
<link href="http://purl.org/dc/elements/1.1/" rel="schema.DC">
<meta content="Schönwiesner, Marc" name="DC.contributor">
<meta content="Bengio, Yoshua" name="DC.contributor">
<meta content="Thompson, Jessica A. F." name="DC.creator">
<meta content="2021-01-29T15:24:21Z" name="DCTERMS.dateAccepted" scheme="DCTERMS.W3CDTF">
<meta content="NO_RESTRICTION" name="DCTERMS.available" scheme="DCTERMS.W3CDTF" xml:lang="fr">
<meta content="2021-01-29T15:24:21Z" name="DCTERMS.available" scheme="DCTERMS.W3CDTF">
<meta content="2020-12-16" name="DCTERMS.issued" scheme="DCTERMS.W3CDTF"/>
<meta content="2020-04" name="DC.date" scheme="DCTERMS.W3CDTF"/>
<meta content="http://hdl.handle.net/1866/24665" name="DC.identifier" scheme="DCTERMS.URI"/>
<meta content="deep learning" name="DC.subject" xml:lang="fr"/>
<meta content="audition" name="DC.subject" xml:lang="fr"/>
<meta content="computational neuroscience" name="DC.subject" xml:lang="fr"/>
<meta content="fMRI" name="DC.subject" xml:lang="fr"/>
<meta content="speech" name="DC.subject" xml:lang="fr"/>
<meta content="similarity analysis" name="DC.subject" xml:lang="fr"/>
<meta content="apprentissage profond" name="DC.subject" xml:lang="fr"/>
<meta content="neurosciences computationnelles" name="DC.subject" xml:lang="fr"/>
<meta content="IRMf" name="DC.subject" xml:lang="fr"/>
<meta content="parole" name="DC.subject" xml:lang="fr"/>
<meta content="analyse de similarité" name="DC.subject" xml:lang="fr"/>
<meta content="Psychology - Cognitive / Psychologie cognitive (UMI : 0633)" name="DC.subject" xml:lang="fr"/>
<meta content="Characterizing and comparing acoustic representations in convolutional neural networks and the human auditory system" name="DC.title" xml:lang="fr"/>
<meta content="Thèse ou mémoire / Thesis or Dissertation" name="DC.type"/>
<meta content="Le traitement auditif dans le cerveau humain et dans les systèmes informatiques consiste en une cascade de transformations représentationnelles qui extraient et réorganisent les informations pertinentes pour permettre l'exécution des tâches. Cette thèse s'intéresse à la nature des représentations acoustiques et aux principes de conception et d'apprentissage qui soutiennent leur développement. Les objectifs scientifiques sont de caractériser et de comparer les représentations auditives dans les réseaux de neurones convolutionnels profonds (CNN) et la voie auditive humaine. Ce travail soulève plusieurs questions méta-scientifiques sur la nature du progrès scientifique, qui sont également considérées.

L'introduction passe en revue les connaissances actuelles sur la voie auditive des mammifères et présente les concepts pertinents de l'apprentissage profond. Le premier article soutient que les questions philosophiques les plus pressantes à l'intersection de l'intelligence artificielle et biologique concernent finalement la définition des phénomènes à expliquer et ce qui constitue des explications valables de tels phénomènes. Je surligne les théories pertinentes de l'explication scientifique que j’espére fourniront un échafaudage pour de futures discussions. L'article 2 teste un modèle populaire de cortex auditif basé sur des modulations spectro-temporelles. Nous constatons qu'un modèle linéaire entraîné uniquement sur les réponses BOLD aux ondulations dynamiques simples (contenant seulement une fréquence fondamentale, un taux de modulation temporelle et une échelle spectrale) peut se généraliser pour prédire les réponses aux mélanges de deux ondulations dynamiques. Le troisième article caractérise la spécificité linguistique des couches CNN et explore l'effet de l'entraînement figé et des poids aléatoires. Nous avons observé trois régions distinctes de transférabilité: (1) les deux premières couches étaient entièrement transférables, (2) les couches 2 à 8 étaient également hautement transférables, mais nous avons trouvé évidence de spécificité de la langue, (3) les couches suivantes entièrement connectées étaient plus spécifiques à la langue mais pouvaient être adaptées sur la langue cible. Dans l'article 4, nous utilisons l'analyse de similarité pour constater que la performance supérieure de l'entraînement figé obtenues à l'article 3 peuvent être attribuées aux différences de représentation dans l'avant-dernière couche: la deuxième couche entièrement connectée. Nous analysons également les réseaux aléatoires de l'article 3, dont nous concluons que la forme représentationnelle est doublement contrainte par l'architecture et la forme de l'entrée et de la cible. Pour tester si les CNN acoustiques apprennent une hiérarchie de représentation similaire à celle du système auditif humain, le cinquième article compare l'activité des réseaux «freeze trained» de l'article 3 à l'activité IRMf 7T dans l'ensemble du système auditif humain. Nous ne trouvons aucune évidence d'une hiérarchie de représentation partagée et constatons plutôt que tous nos régions auditifs étaient les plus similaires à la première couche entièrement connectée. Enfin, le chapitre de discussion passe en revue les mérites et les limites d'une approche d'apprentissage profond aux neurosciences dans un cadre de comparaison de modèles.

Ensemble, ces travaux contribuent à l'entreprise naissante de modélisation du système auditif avec des réseaux de neurones et constituent un petit pas vers une science unifiée de l'intelligence qui étudie les phénomènes qui se manifestent dans l'intelligence biologique et artificielle." name="DCTERMS.abstract" xml:lang="fr"/>
<meta content="Auditory processing in the human brain and in contemporary machine hearing systems consists of a cascade of representational transformations that extract and reorganize relevant information to enable task performance. This thesis is concerned with the nature of acoustic representations and the network design and learning principles that support their development. The primary scientific goals are to characterize and compare auditory representations in deep convolutional neural networks (CNNs) and the human auditory pathway. This work prompts several meta-scientific questions about the nature of scientific progress, which are also considered. 

The introduction reviews what is currently known about the mammalian auditory pathway and introduces the relevant concepts in deep learning.The first article argues that the most pressing philosophical questions at the intersection of artificial and biological intelligence are ultimately concerned with defining the phenomena to be explained and with what constitute valid explanations of such phenomena. I highlight relevant theories of scientific explanation which we hope will provide scaffolding for future discussion. Article 2 tests a popular model of auditory cortex based on frequency-specific spectrotemporal modulations. We find that a linear model trained only on BOLD responses to simple dynamic ripples (containing only one fundamental frequency, temporal modulation rate, and spectral scale) can generalize to predict responses to mixtures of two dynamic ripples. Both the third and fourth article investigate how CNN representations are affected by various aspects of training. The third article characterizes the language specificity of CNN layers and explores the effect of freeze training and random weights. We observed three distinct regions of transferability: (1) the first two layers were entirely transferable between languages, (2) layers 2--8 were also highly transferable but we found some evidence of language specificity, (3) the subsequent fully connected layers were more language specific but could be successfully finetuned to the target language. In Article 4, we use similarity analysis to find that the superior performance of freeze training achieved in Article 3 can be largely attributed to representational differences in the penultimate layer: the second fully connected layer. We also analyze the random networks from Article 3, from which we conclude that representational form is doubly constrained by architecture and the form of the input and target. To test whether acoustic CNNs learn a similar representational hierarchy as that of the human auditory system, the fifth article presents a similarity analysis to compare the activity of the freeze trained networks from Article 3 to 7T fMRI activity throughout the human auditory system. We find no evidence of a shared representational hierarchy and instead find that all of our auditory regions were most similar to the first fully connected layer. Finally, the discussion chapter reviews the merits and limitations of a deep learning approach to neuroscience in a model comparison framework. 

Together, these works contribute to the nascent enterprise of modeling the auditory system with neural networks and constitute a small step towards a unified science of intelligence that studies the phenomena that are exhibited in both biological and artificial intelligence." name="DCTERMS.abstract" xml:lang="fr"/>
<meta content="eng" name="DCTERMS.language" xml:lang="fr"/>
<meta content="deep learning; audition; computational neuroscience; fMRI; speech; similarity analysis; apprentissage profond; neurosciences computationnelles; IRMf; parole; analyse de similarité; Psychology - Cognitive / Psychologie cognitive (UMI : 0633); Thèse ou mémoire / Thesis or Dissertation; Psychologie" name="citation_keywords"/>
<meta content="Characterizing and comparing acoustic representations in convolutional neural networks and the human auditory system" name="citation_title"/>
<meta content="eng" name="citation_language"/>
<meta content="Thompson, Jessica A. F." name="citation_author"/>
<meta content="https://papyrus.bib.umontreal.ca/xmlui/bitstream/1866/24665/2/Thompson_Jessica_2020_these.pdf" name="citation_pdf_url"/>
<meta content="2020-12-16" name="citation_date"/>
<meta content="https://papyrus.bib.umontreal.ca/xmlui/handle/1866/24665" name="citation_abstract_html_url"/>
<script type="text/x-mathjax-config">
                    MathJax.Hub.Config({
                      tex2jax: {
                        inlineMath: [['\\(','\\)']],
                        ignoreClass: "detail-field-data|detailtable|exception"
                      },
                      TeX: {
                        Macros: {
                          AA: '{\\mathring A}'
                        }
                      }
                    });
                </script><script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"> </script>
</meta></meta></meta></meta></meta></meta></link></link></head><body>
<header>
<div class="navbar navbar-default navbar-static-top" role="navigation">
<div class="container">
<div class="hidden-xs hidden-sm hidden-md" id="um-bandeau" role="banner">
<nav class="um-nav um-nav-hidden" role="navigation">
<span class="hidden">Liens externes</span>
<ul>
<li>
<a href="https://www.umontreal.ca/#udemwww-search-personne">Directories</a>
</li>
<li>
<a href="http://www.umontreal.ca/repertoires/facultes.html">Faculties</a>
</li>
<li>
<a href="http://www.bib.umontreal.ca/">Libraries</a>
</li>
<li>
<a href="http://plancampus.umontreal.ca/">Campus maps</a>
</li>
<li>
<a href="http://www.umontreal.ca/index/az.html">Sites A to Z</a>
</li>
<li>
<a>My UdeM</a>
<ul>
<li>
<a href="https://monudem.umontreal.ca/">My UdeM Portal</a>
</li>
<li>
<a href="https://outlook.umontreal.ca">My email</a>
</li>
<li>
<a href="https://studium.umontreal.ca/">StudiUM</a>
</li>
</ul>
</li>
</ul>
</nav>
<form action="https://google.com/cse" class="um-recherche" id="um-recherche" role="search">
<input name="cx" type="hidden" value="011926736769028447783:qlpu3so2kqq"/><input name="ie" type="hidden" value="ISO-8859-1"/><label class="hidden" for="um-boite-recherche">Search in : </label><span class="um-boite-bouton"><input class="um-boite" id="um-boite-recherche" maxlength="255" name="q" placeholder="UdeM" title="Type your search text" type="text" value=""/><input alt="Search in : " class="um-bouton" src="/xmlui/themes/Mirage2/images/bib-umontreal/loupe.gif" type="image"/></span>
</form>
</div>
<div class="hidden-xs hidden-sm visible-md visible-lg" id="papyrus-deco">
<img alt="Dessin du pavillon Roger Gaudry/Sketch of Roger Gaudry Building" border="0" height="89px" src="/xmlui/themes/Mirage2/images/UdeM.gif" title="Dessin du pavillon Roger Gaudry/Sketch of Roger Gaudry Building" width="193px"/></div>
<div class="navbar-header">
<button class="navbar-toggle" data-toggle="offcanvas" type="button"><span class="sr-only">Toggle navigation</span><span class="icon-bar"></span><span class="icon-bar"></span><span class="icon-bar"></span></button><a class="navbar-brand hidden-xs hidden-sm visible-md visible-lg um-logo-md-lg" href="http://www.umontreal.ca/english/index.html"><img alt="University Home page" src="/xmlui/themes/Mirage2/images/logo-UdeM.svg" title="Back to University Home page"/></a><a class="navbar-brand hidden-xs visible-sm hidden-md hidden-lg um-logo-sm" href="http://www.umontreal.ca/english/index.html"><img alt="University Home page" src="/xmlui/themes/Mirage2/images/logo-UdeM.svg" title="Back to University Home page"/></a><a class="navbar-brand visible-xs hidden-sm hidden-md hidden-lg um-logo-xs" href="http://www.umontreal.ca/english/index.html"><img alt="University Home page" src="/xmlui/themes/Mirage2/images/logo-UdeM.svg" title="Back to University Home page"/></a>
<div class="navbar-brand separateur visible-xs hidden-sm hidden-md hidden-lg um-sep-site-xs"></div>
<div class="navbar-brand separateur hidden-xs visible-sm hidden-md hidden-lg um-sep-site-sm"></div>
<div class="navbar-brand separateur visible-md visible-lg hidden-xs hidden-sm um-sep-site-md-lg"></div>
<div class="navbar-brand visible-md visible-lg hidden-xs hidden-sm um-titre-site-md-lg">
<span class="papyrus-signature">Papyrus</span> :
                                Institutional Repository</div>
<div class="navbar-brand hidden-xs visible-sm hidden-md hidden-lg um-titre-site-sm">
<span class="papyrus-signature">Papyrus</span>
<br/>Institutional Repository</div>
<div class="navbar-brand visible-xs hidden-sm hidden-md hidden-lg um-titre-site-xs">
<span class="papyrus-signature">Papyrus</span>
</div>
<div class="navbar-header pull-right visible-xs hidden-sm hidden-md hidden-lg">
<ul class="nav nav-pills pull-left">
<li class="dropdown" id="ds-language-selection-xs">
<button class="dropdown-toggle navbar-toggle navbar-link" data-toggle="dropdown" href="#" id="language-dropdown-toggle-xs" role="button"><b aria-hidden="true" class="visible-xs glyphicon glyphicon-globe"></b></button>
<ul aria-labelledby="language-dropdown-toggle-xs" class="dropdown-menu pull-right" data-no-collapse="true" role="menu">
<li role="presentation">
<a href="https://papyrus.bib.umontreal.ca:443/xmlui/handle/1866/24665?locale-attribute=fr&amp;show=full">français</a>
</li>
<li class="disabled" role="presentation">
<a href="https://papyrus.bib.umontreal.ca:443/xmlui/handle/1866/24665?locale-attribute=en&amp;show=full">English</a>
</li>
</ul>
</li>
<li>
<form action="/xmlui/login" method="get" style="display: inline">
<button class="navbar-toggle navbar-link"><b aria-hidden="true" class="visible-xs glyphicon glyphicon-user"></b></button>
</form>
</li>
</ul>
</div>
</div>
<div class="navbar-header pull-right hidden-xs">
<div class="nav-language-and-login-lg hidden-xs hidden-sm hidden-md">
<ul class="nav navbar-nav pull-right">
<li class="dropdown" id="ds-language-selection">
<a class="dropdown-toggle" data-toggle="dropdown" href="#" id="language-dropdown-toggle" role="button"><span class="hidden-xs">English <b class="caret"></b></span></a>
<ul aria-labelledby="language-dropdown-toggle" class="dropdown-menu pull-right" data-no-collapse="true" role="menu">
<li role="presentation">
<a href="https://papyrus.bib.umontreal.ca:443/xmlui/handle/1866/24665?locale-attribute=fr&amp;show=full">français</a>
</li>
<li class="disabled" role="presentation">
<a href="https://papyrus.bib.umontreal.ca:443/xmlui/handle/1866/24665?locale-attribute=en&amp;show=full">English</a>
</li>
</ul>
</li>
</ul>
<ul class="nav navbar-nav pull-right">
<li>
<a href="/xmlui/login"><span class="hidden-xs">Login</span></a>
</li>
</ul>
</div>
<div class="hidden-lg">
<ul class="nav navbar-nav pull-right">
<li class="dropdown" id="ds-language-selection">
<a class="dropdown-toggle" data-toggle="dropdown" href="#" id="language-dropdown-toggle" role="button"><span class="hidden-xs">English <b class="caret"></b></span></a>
<ul aria-labelledby="language-dropdown-toggle" class="dropdown-menu pull-right" data-no-collapse="true" role="menu">
<li role="presentation">
<a href="https://papyrus.bib.umontreal.ca:443/xmlui/handle/1866/24665?locale-attribute=fr&amp;show=full">français</a>
</li>
<li class="disabled" role="presentation">
<a href="https://papyrus.bib.umontreal.ca:443/xmlui/handle/1866/24665?locale-attribute=en&amp;show=full">English</a>
</li>
</ul>
</li>
</ul>
<ul class="nav navbar-nav pull-right">
<li>
<a href="/xmlui/login"><span class="hidden-xs">Login</span></a>
</li>
</ul>
</div>
<button class="navbar-toggle visible-sm" data-toggle="offcanvas" type="button"><span class="sr-only">Toggle navigation</span><span class="icon-bar"></span><span class="icon-bar"></span><span class="icon-bar"></span></button>
</div>
</div>
</div>
</header>
<div class="trail-wrapper hidden-print">
<div class="container">
<div class="row">
<div class="col-xs-12">
<div class="breadcrumb dropdown visible-xs">
<a class="dropdown-toggle" data-toggle="dropdown" href="#" id="trail-dropdown-toggle" role="button">View Item <b class="caret"></b></a>
<ul aria-labelledby="trail-dropdown-toggle" class="dropdown-menu" role="menu">
<li role="presentation">
<a href="/xmlui/" role="menuitem"><i aria-hidden="true" class="glyphicon glyphicon-home"></i>  Home</a>
</li>
<li role="presentation">
<a href="/xmlui/handle/1866/3010" role="menuitem">Faculté des arts et des sciences</a>
</li>
<li role="presentation">
<a href="/xmlui/handle/1866/2951" role="menuitem">Faculté des arts et des sciences – Département de psychologie</a>
</li>
<li role="presentation">
<a href="/xmlui/handle/1866/2991" role="menuitem">Faculté des arts et des sciences – Département de psychologie - Thèses et mémoires</a>
</li>
<li class="disabled" role="presentation">
<a href="#" role="menuitem">View Item</a>
</li>
</ul>
</div>
<ul class="breadcrumb hidden-xs">
<li>
<i aria-hidden="true" class="glyphicon glyphicon-home"></i>  <a href="/xmlui/">Home</a>
</li>
<li>
<a href="/xmlui/handle/1866/3010">Faculté des arts et des sciences</a>
</li>
<li>
<a href="/xmlui/handle/1866/2951">Faculté des arts et des sciences – Département de psychologie</a>
</li>
<li>
<a href="/xmlui/handle/1866/2991">Faculté des arts et des sciences – Département de psychologie - Thèses et mémoires</a>
</li>
<li class="active">View Item</li>
</ul>
</div>
</div>
</div>
</div>
<div class="hidden" id="no-js-warning-wrapper">
<div id="no-js-warning">
<div class="notice failure">JavaScript is disabled for your browser. Some features of this site may not work without it.</div>
</div>
</div>
<div class="container" id="main-container">
<div class="row row-offcanvas row-offcanvas-left">
<div class="horizontal-slider clearfix">
<div class="col-xs-6 col-sm-3 sidebar-offcanvas" id="sidebar" role="navigation">
<div class="word-break hidden-print" id="ds-options">
<div class="ds-option-set" id="ds-search-option">
<form action="/xmlui/discover" class="" id="ds-search-form" method="post">
<fieldset>
<div class="input-group">
<input class="ds-text-field form-control" name="query" placeholder="Search" type="text"/><span class="input-group-btn"><button class="ds-button-field btn" title="Go"><span aria-hidden="true" class="glyphicon glyphicon-search"></span></button></span>
</div>
<div class="radio">
<label><input checked="" id="ds-search-form-scope-all" name="scope" type="radio" value=""/>Search Papyrus</label>
</div>
<div class="radio">
<label><input id="ds-search-form-scope-container" name="scope" type="radio" value="1866/2991"/>Search this Collection</label>
</div>
</fieldset>
</form>
</div>
<h2 class="ds-option-set-head h6">My Account</h2>
<div class="list-group" id="aspect_viewArtifacts_Navigation_list_account">
<div class="list-group-item ds-option details_Papyrus" id="aspect_eperson_Navigation_item_details_Papyrus">To submit an item or subscribe to email alerts.</div>
<div class="list-group-item ds-option">
<span class="bold"><a href="/xmlui/login">Login</a></span>
</div>
<a class="list-group-item ds-option" href="/xmlui/register">New user?</a>
</div>
<h2 class="ds-option-set-head h6">Browse</h2>
<div class="list-group" id="aspect_viewArtifacts_Navigation_list_browse">
<a class="list-group-item active"><span class="h5 list-group-item-heading h5">All of Papyrus</span></a><a class="list-group-item ds-option" href="/xmlui/community-list">Communities and Collections</a><a class="list-group-item ds-option" href="/xmlui/browse?type=title">Titles</a><a class="list-group-item ds-option" href="/xmlui/browse?type=dateissued">Issue Dates</a><a class="list-group-item ds-option" href="/xmlui/browse?type=author">Authors</a><a class="list-group-item ds-option" href="/xmlui/browse?type=advisor">Advisors</a><a class="list-group-item ds-option" href="/xmlui/browse?type=subject">Subjects</a><a class="list-group-item ds-option" href="/xmlui/browse?type=discipline">Disciplines</a><a class="list-group-item ds-option" href="/xmlui/browse?type=affiliation">Affiliation</a><a class="list-group-item ds-option" href="/xmlui/browse?type=titleindex">Titles index</a><a class="list-group-item active"><span class="h5 list-group-item-heading h5">This Collection</span></a><a class="list-group-item ds-option" href="/xmlui/handle/1866/2991/browse?type=title">Titles</a><a class="list-group-item ds-option" href="/xmlui/handle/1866/2991/browse?type=dateissued">Issue Dates</a><a class="list-group-item ds-option" href="/xmlui/handle/1866/2991/browse?type=author">Authors</a><a class="list-group-item ds-option" href="/xmlui/handle/1866/2991/browse?type=advisor">Advisors</a><a class="list-group-item ds-option" href="/xmlui/handle/1866/2991/browse?type=subject">Subjects</a><a class="list-group-item ds-option" href="/xmlui/handle/1866/2991/browse?type=discipline">Disciplines</a><a class="list-group-item ds-option" href="/xmlui/handle/1866/2991/browse?type=affiliation">Affiliation</a><a class="list-group-item ds-option" href="/xmlui/handle/1866/2991/browse?type=titleindex">Titles index</a>
</div>
<div class="list-group" id="aspect_viewArtifacts_Navigation_list_context"></div>
<div class="list-group" id="aspect_viewArtifacts_Navigation_list_administrative"></div>
<div class="list-group" id="aspect_discovery_Navigation_list_discovery"></div>
<h2 class="ds-option-set-head h6">Statistics</h2>
<div class="list-group" id="aspect_statistics_Navigation_list_statistics">
<a class="list-group-item ds-option" href="/xmlui/handle/1866/24665/statistics">View Usage Statistics</a>
</div>
</div>
</div>
<div class="col-xs-12 col-sm-12 col-md-9 main-content">
<div>
<div class="ds-static-div primary" id="aspect_artifactbrowser_ItemViewer_div_item-view">
<p class="ds-paragraph item-view-toggle item-view-toggle-top">
<span class="item-view-toggle"><a href="/xmlui/handle/1866/24665">Show item record</a></span>
</p>
<!-- External Metadata URL: cocoon://metadata/handle/1866/24665/mets.xml-->
<h2 class="page-header first-page-header">Characterizing and comparing acoustic representations in convolutional neural networks and the human auditory system</h2>
<div class="ds-table-responsive">
<table class="ds-includeSet-table detailtable table table-striped table-hover">
<tr class="ds-table-row odd">
<td class="label-cell">dc.contributor.advisor</td><td class="word-break">Schönwiesner, Marc</td><td></td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.contributor.advisor</td><td class="word-break">Bengio, Yoshua</td><td></td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.contributor.author</td><td class="word-break">Thompson, Jessica A. F.</td><td></td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.date.accessioned</td><td class="word-break">2021-01-29T15:24:21Z</td><td></td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.date.available</td><td class="word-break">NO_RESTRICTION</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.date.available</td><td class="word-break">2021-01-29T15:24:21Z</td><td></td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.date.issued</td><td class="word-break">2020-12-16</td><td></td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.date.submitted</td><td class="word-break">2020-04</td><td></td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.identifier.uri</td><td class="word-break">http://hdl.handle.net/1866/24665</td><td></td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">deep learning</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject</td><td class="word-break">audition</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">computational neuroscience</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject</td><td class="word-break">fMRI</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">speech</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject</td><td class="word-break">similarity analysis</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">apprentissage profond</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject</td><td class="word-break">neurosciences computationnelles</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">IRMf</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject</td><td class="word-break">parole</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">analyse de similarité</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject.other</td><td class="word-break">Psychology - Cognitive / Psychologie cognitive (UMI : 0633)</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.title</td><td class="word-break">Characterizing and comparing acoustic representations in convolutional neural networks and the human auditory system</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.type</td><td class="word-break">Thèse ou mémoire / Thesis or Dissertation</td><td></td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">etd.degree.discipline</td><td class="word-break">Psychologie</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">etd.degree.grantor</td><td class="word-break">Université de Montréal</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">etd.degree.level</td><td class="word-break">Doctorat / Doctoral</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">etd.degree.name</td><td class="word-break">Ph. D.</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dcterms.abstract</td><td class="word-break">Le traitement auditif dans le cerveau humain et dans les systèmes informatiques consiste en une cascade de transformations représentationnelles qui extraient et réorganisent les informations pertinentes pour permettre l'exécution des tâches. Cette thèse s'intéresse à la nature des représentations acoustiques et aux principes de conception et d'apprentissage qui soutiennent leur développement. Les objectifs scientifiques sont de caractériser et de comparer les représentations auditives dans les réseaux de neurones convolutionnels profonds (CNN) et la voie auditive humaine. Ce travail soulève plusieurs questions méta-scientifiques sur la nature du progrès scientifique, qui sont également considérées.

L'introduction passe en revue les connaissances actuelles sur la voie auditive des mammifères et présente les concepts pertinents de l'apprentissage profond. Le premier article soutient que les questions philosophiques les plus pressantes à l'intersection de l'intelligence artificielle et biologique concernent finalement la définition des phénomènes à expliquer et ce qui constitue des explications valables de tels phénomènes. Je surligne les théories pertinentes de l'explication scientifique que j’espére fourniront un échafaudage pour de futures discussions. L'article 2 teste un modèle populaire de cortex auditif basé sur des modulations spectro-temporelles. Nous constatons qu'un modèle linéaire entraîné uniquement sur les réponses BOLD aux ondulations dynamiques simples (contenant seulement une fréquence fondamentale, un taux de modulation temporelle et une échelle spectrale) peut se généraliser pour prédire les réponses aux mélanges de deux ondulations dynamiques. Le troisième article caractérise la spécificité linguistique des couches CNN et explore l'effet de l'entraînement figé et des poids aléatoires. Nous avons observé trois régions distinctes de transférabilité: (1) les deux premières couches étaient entièrement transférables, (2) les couches 2 à 8 étaient également hautement transférables, mais nous avons trouvé évidence de spécificité de la langue, (3) les couches suivantes entièrement connectées étaient plus spécifiques à la langue mais pouvaient être adaptées sur la langue cible. Dans l'article 4, nous utilisons l'analyse de similarité pour constater que la performance supérieure de l'entraînement figé obtenues à l'article 3 peuvent être attribuées aux différences de représentation dans l'avant-dernière couche: la deuxième couche entièrement connectée. Nous analysons également les réseaux aléatoires de l'article 3, dont nous concluons que la forme représentationnelle est doublement contrainte par l'architecture et la forme de l'entrée et de la cible. Pour tester si les CNN acoustiques apprennent une hiérarchie de représentation similaire à celle du système auditif humain, le cinquième article compare l'activité des réseaux «freeze trained» de l'article 3 à l'activité IRMf 7T dans l'ensemble du système auditif humain. Nous ne trouvons aucune évidence d'une hiérarchie de représentation partagée et constatons plutôt que tous nos régions auditifs étaient les plus similaires à la première couche entièrement connectée. Enfin, le chapitre de discussion passe en revue les mérites et les limites d'une approche d'apprentissage profond aux neurosciences dans un cadre de comparaison de modèles.

Ensemble, ces travaux contribuent à l'entreprise naissante de modélisation du système auditif avec des réseaux de neurones et constituent un petit pas vers une science unifiée de l'intelligence qui étudie les phénomènes qui se manifestent dans l'intelligence biologique et artificielle.</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dcterms.abstract</td><td class="word-break">Auditory processing in the human brain and in contemporary machine hearing systems consists of a cascade of representational transformations that extract and reorganize relevant information to enable task performance. This thesis is concerned with the nature of acoustic representations and the network design and learning principles that support their development. The primary scientific goals are to characterize and compare auditory representations in deep convolutional neural networks (CNNs) and the human auditory pathway. This work prompts several meta-scientific questions about the nature of scientific progress, which are also considered. 

The introduction reviews what is currently known about the mammalian auditory pathway and introduces the relevant concepts in deep learning.The first article argues that the most pressing philosophical questions at the intersection of artificial and biological intelligence are ultimately concerned with defining the phenomena to be explained and with what constitute valid explanations of such phenomena. I highlight relevant theories of scientific explanation which we hope will provide scaffolding for future discussion. Article 2 tests a popular model of auditory cortex based on frequency-specific spectrotemporal modulations. We find that a linear model trained only on BOLD responses to simple dynamic ripples (containing only one fundamental frequency, temporal modulation rate, and spectral scale) can generalize to predict responses to mixtures of two dynamic ripples. Both the third and fourth article investigate how CNN representations are affected by various aspects of training. The third article characterizes the language specificity of CNN layers and explores the effect of freeze training and random weights. We observed three distinct regions of transferability: (1) the first two layers were entirely transferable between languages, (2) layers 2--8 were also highly transferable but we found some evidence of language specificity, (3) the subsequent fully connected layers were more language specific but could be successfully finetuned to the target language. In Article 4, we use similarity analysis to find that the superior performance of freeze training achieved in Article 3 can be largely attributed to representational differences in the penultimate layer: the second fully connected layer. We also analyze the random networks from Article 3, from which we conclude that representational form is doubly constrained by architecture and the form of the input and target. To test whether acoustic CNNs learn a similar representational hierarchy as that of the human auditory system, the fifth article presents a similarity analysis to compare the activity of the freeze trained networks from Article 3 to 7T fMRI activity throughout the human auditory system. We find no evidence of a shared representational hierarchy and instead find that all of our auditory regions were most similar to the first fully connected layer. Finally, the discussion chapter reviews the merits and limitations of a deep learning approach to neuroscience in a model comparison framework. 

Together, these works contribute to the nascent enterprise of modeling the auditory system with neural networks and constitute a small step towards a unified science of intelligence that studies the phenomena that are exhibited in both biological and artificial intelligence.</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dcterms.language</td><td class="word-break">eng</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">UdeM.ORCIDAuteurThese</td><td class="word-break">0000-0003-0468-5097</td><td>fr</td>
</tr>
</table>
</div>
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc&amp;rft_id=http%3A%2F%2Fhdl.handle.net%2F1866%2F24665&amp;rfr_id=info%3Asid%2Fdspace.org%3Arepository&amp;rft.degree=Psychologie&amp;rft.degree=Universit%C3%A9+de+Montr%C3%A9al&amp;rft.degree=Doctorat+%2F+Doctoral&amp;rft.degree=Ph.+D."> ﻿ 
        </span>
<h3>Files in this item</h3>
<div class="file-list">
<div class="file-wrapper row">
<div class="col-xs-6 col-sm-3">
<div class="thumbnail-wrapper">
<a class="image-link" href="/xmlui/bitstream/handle/1866/24665/Thompson_Jessica_2020_these.pdf?sequence=2&amp;isAllowed=y"><img alt="Thumbnail" class="thumbnail-papyrus" src="/xmlui/bitstream/handle/1866/24665/Thompson_Jessica_2020_these.pdf.jpg?sequence=4&amp;isAllowed=y"/></a>
<div class="imageoverlay">
<img height="49" src="/xmlui/themes/Mirage2/images/mimes/mime_icone_pdf.png" style="height: 49px;" width="44"/></div>
</div>
</div>
<div class="col-xs-6 col-sm-7">
<dl class="file-metadata dl-horizontal">
<dt>Name:</dt>
<dd class="word-break" title="Thompson_Jessica_2020_these.pdf">
<a href="/xmlui/bitstream/handle/1866/24665/Thompson_Jessica_2020_these.pdf?sequence=2&amp;isAllowed=y">Thompson_Jessica_2020_these.pdf</a>
</dd>
<dt>Size:</dt>
<dd class="word-break">11.14Mb</dd>
<dt>Format:</dt>
<dd class="word-break">PDF</dd>
<dt>Description:</dt>
<dd class="word-break" title="Thèse">Thèse</dd>
</dl>
</div>
</div>
</div>
<h3 class="ds-list-head">This item appears in the following Collection(s)</h3>
<ul class="ds-referenceSet-list">
<!-- External Metadata URL: cocoon://metadata/handle/1866/2621/mets.xml-->
<li>
<a href="/xmlui/handle/1866/2621">Thèses et mémoires électroniques de l’Université de Montréal</a> [18270]<br/>
</li>
<!-- External Metadata URL: cocoon://metadata/handle/1866/2991/mets.xml-->
<li>
<a href="/xmlui/handle/1866/2991">Faculté des arts et des sciences – Département de psychologie - Thèses et mémoires</a> [864]<br/>
</li>
</ul>
<p class="ds-paragraph item-view-toggle item-view-toggle-bottom">
<span class="item-view-toggle"><a href="/xmlui/handle/1866/24665">Show item record</a></span>
</p>
</div>
</div>
<div class="visible-xs visible-sm">
<footer>
<div class="row">
<hr/>
<div class="col-xs-7 col-sm-8">
<div>
<a href="http://www.dspace.org/" target="_blank">DSpace software</a>
                        [version 5.8 XMLUI],
                        copyright © 2002-2015  <a href="http://www.duraspace.org/" target="_blank">DuraSpace</a>
</div>
<div class="hidden-print">
<a href="/xmlui/contact">Contact Us</a> | <a href="/xmlui/feedback">Send Feedback</a>
</div>
</div>
<div class="col-xs-5 col-sm-4 hidden-print">
<div class="pull-right">
<script type="text/javascript"> 
										      (function(d, t) { 
										        var s = d.createElement(t), options = {'domain':'papyrus.bib.umontreal.ca','style': '16','container':'entrust-net-seal'}; 
										        s.src = 'https://seal.entrust.net/sealv2.js'; 
										        s.async = true; 
										        var scr = d.getElementsByTagName(t)[0], par = scr.parentNode; par.insertBefore(s, scr); 
										        s.onload = s.onreadystatechange = function() { 
										        var rs = this.readyState; if (rs) if (rs != 'complete') if (rs != 'loaded') return; 
										        try{goEntrust(options)} catch (e) {} }; 
										        })(document, 'script'); 
										</script>
<div id="entrust-net-seal">
<a href="https://www.entrust.com/ssl-certificates/">Certificat SSL / SSL Certificate</a>
</div>
</div>
</div>
</div>
<div class="row bib-footer hidden-print">
<div class="col-xs-12 col-sm-12 col-md-4">
<a class="footerEXLlink" href="http://www.bib.umontreal.ca"><img alt="les bibliothèques/UdeM" src="/xmlui/themes/Mirage2/images/propulse-par.png"/></a>
</div>
<div class="hidden-xs col-sm-12 col-md-8">
<nav>
<ul>
<li>
<a href="https://www.urgence.umontreal.ca/">Emergency</a>
</li>
<li>
<a href="http://www.carrieres.umontreal.ca/">Careers</a>
</li>
<li>
<a href="https://outlook.umontreal.ca/">My email</a>
</li>
<li>
<a href="https://studium.umontreal.ca/">StudiUM</a>
</li>
<li>
<a href="http://itunesu.umontreal.ca/">iTunes U</a>
</li>
<li>
<a href="http://www.bib.umontreal.ca/a-propos/nous-ecrire.htm">Contact us</a>
</li>
<li>
<a href="https://www.facebook.com/bibUdeM"><img alt="Facebook" src="/xmlui/themes/Mirage2/images/bib-umontreal/logo-Facebook.png"/></a>
</li>
<li>
<a href="https://www.youtube.com/user/BibliothequesUdeM"><img alt="YouTube" src="/xmlui/themes/Mirage2/images/bib-umontreal/logo-YouTube.png"/></a>
</li>
<li>
<a href="https://twitter.com/bibUdeM"><img alt="Twitter" src="/xmlui/themes/Mirage2/images/bib-umontreal/logo-Twitter.png"/></a>
</li>
<li>
<a href="https://www.nouvelles.umontreal.ca/frontpage/rss.html"><img alt="University RSS" src="/xmlui/themes/Mirage2/images/bib-umontreal/icone-syndication-14x14.png"/></a>
</li>
</ul>
</nav>
</div>
</div>
<a class="hidden" href="/xmlui/htmlmap"> </a>
<p> </p>
</footer>
</div>
</div>
</div>
</div>
<div class="hidden-xs hidden-sm">
<footer>
<div class="row">
<hr/>
<div class="col-xs-7 col-sm-8">
<div>
<a href="http://www.dspace.org/" target="_blank">DSpace software</a>
                        [version 5.8 XMLUI],
                        copyright © 2002-2015  <a href="http://www.duraspace.org/" target="_blank">DuraSpace</a>
</div>
<div class="hidden-print">
<a href="/xmlui/contact">Contact Us</a> | <a href="/xmlui/feedback">Send Feedback</a>
</div>
</div>
<div class="col-xs-5 col-sm-4 hidden-print">
<div class="pull-right">
<script type="text/javascript"> 
										      (function(d, t) { 
										        var s = d.createElement(t), options = {'domain':'papyrus.bib.umontreal.ca','style': '16','container':'entrust-net-seal'}; 
										        s.src = 'https://seal.entrust.net/sealv2.js'; 
										        s.async = true; 
										        var scr = d.getElementsByTagName(t)[0], par = scr.parentNode; par.insertBefore(s, scr); 
										        s.onload = s.onreadystatechange = function() { 
										        var rs = this.readyState; if (rs) if (rs != 'complete') if (rs != 'loaded') return; 
										        try{goEntrust(options)} catch (e) {} }; 
										        })(document, 'script'); 
										</script>
<div id="entrust-net-seal">
<a href="https://www.entrust.com/ssl-certificates/">Certificat SSL / SSL Certificate</a>
</div>
</div>
</div>
</div>
<div class="row bib-footer hidden-print">
<div class="col-xs-12 col-sm-12 col-md-4">
<a class="footerEXLlink" href="http://www.bib.umontreal.ca"><img alt="les bibliothèques/UdeM" src="/xmlui/themes/Mirage2/images/propulse-par.png"/></a>
</div>
<div class="hidden-xs col-sm-12 col-md-8">
<nav>
<ul>
<li>
<a href="https://www.urgence.umontreal.ca/">Emergency</a>
</li>
<li>
<a href="http://www.carrieres.umontreal.ca/">Careers</a>
</li>
<li>
<a href="https://outlook.umontreal.ca/">My email</a>
</li>
<li>
<a href="https://studium.umontreal.ca/">StudiUM</a>
</li>
<li>
<a href="http://itunesu.umontreal.ca/">iTunes U</a>
</li>
<li>
<a href="http://www.bib.umontreal.ca/a-propos/nous-ecrire.htm">Contact us</a>
</li>
<li>
<a href="https://www.facebook.com/bibUdeM"><img alt="Facebook" src="/xmlui/themes/Mirage2/images/bib-umontreal/logo-Facebook.png"/></a>
</li>
<li>
<a href="https://www.youtube.com/user/BibliothequesUdeM"><img alt="YouTube" src="/xmlui/themes/Mirage2/images/bib-umontreal/logo-YouTube.png"/></a>
</li>
<li>
<a href="https://twitter.com/bibUdeM"><img alt="Twitter" src="/xmlui/themes/Mirage2/images/bib-umontreal/logo-Twitter.png"/></a>
</li>
<li>
<a href="https://www.nouvelles.umontreal.ca/frontpage/rss.html"><img alt="University RSS" src="/xmlui/themes/Mirage2/images/bib-umontreal/icone-syndication-14x14.png"/></a>
</li>
</ul>
</nav>
</div>
</div>
<a class="hidden" href="/xmlui/htmlmap"> </a>
<p> </p>
</footer>
</div>
</div>
<script src="https://www.google.com/jsapi"> </script><script>if(!window.DSpace){window.DSpace={};}window.DSpace.context_path='/xmlui';window.DSpace.theme_path='/xmlui/themes/Mirage2/';</script><script src="/xmlui/themes/Mirage2/scripts/theme.js"> </script><script>
                  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

                  ga('create', 'UA-305727-1', 'papyrus.bib.umontreal.ca');
                  ga('send', 'pageview');
           </script><script>         
             var details_Papyrus =  $("#aspect_viewArtifacts_Navigation_list_account .details_Papyrus").text();
             $("#aspect_viewArtifacts_Navigation_list_account a[href='/xmlui/login']").attr("title",details_Papyrus);
        </script>
</body></html>
