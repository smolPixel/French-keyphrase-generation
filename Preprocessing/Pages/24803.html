<!DOCTYPE html>

<!--[if lt IE 7]> <html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if IE 7]>    <html class="no-js lt-ie9 lt-ie8" lang="en"> <![endif]-->
<!--[if IE 8]>    <html class="no-js lt-ie9" lang="en"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="/xmlui/themes/Mirage2/images/favicon.ico" rel="shortcut icon"/>
<link href="/xmlui/themes/Mirage2/images/apple-touch-icon.png" rel="apple-touch-icon"/>
<meta content="DSpace 5.8" name="Generator"/>
<link href="https://fonts.googleapis.com/css?family=PT+Sans:400,700|Ubuntu:400,500,700italic|Droid+Sans:400,700" rel="stylesheet" type="text/css"/>
<link href="/xmlui/themes/Mirage2/styles/main.css" rel="stylesheet"/>
<link href="https://papyrus.bib.umontreal.ca:443/xmlui/description.xml" rel="search" title="DSpace" type="application/opensearchdescription+xml"/>
<script>
                //Clear default text of emty text areas on focus
                function tFocus(element)
                {
                if (element.value == ''){element.value='';}
                }
                //Clear default text of emty text areas on submit
                function tSubmit(form)
                {
                var defaultedElements = document.getElementsByTagName("textarea");
                for (var i=0; i != defaultedElements.length; i++){
                if (defaultedElements[i].value == ''){
                defaultedElements[i].value='';}}
                }
                //Disable pressing 'enter' key to submit a form (otherwise pressing 'enter' causes a submission to start over)
                function disableEnterKey(e)
                {
                var key;

                if(window.event)
                key = window.event.keyCode;     //Internet Explorer
                else
                key = e.which;     //Firefox and Netscape

                if(key == 13)  //if "Enter" pressed, then disable!
                return false;
                else
                return true;
                }
            </script><!--[if lt IE 9]>
                <script src="/xmlui/themes/Mirage2/vendor/html5shiv/dist/html5shiv.js"> </script>
                <script src="/xmlui/themes/Mirage2/vendor/respond/respond.min.js"> </script>
                <![endif]--><script src="/xmlui/themes/Mirage2/vendor/modernizr/modernizr.js"> </script><script src="https://www.bib.umontreal.ca/modele/urgence-udem/1.0.0/urgence-udem.js"></script>
<title>Advances in deep learning methods for speech recognition and understanding</title>
<meta content="Dr8axyf94eWBJ8HQjNW4eKxTumAAPsNbvRwpJYMbgGs" name="google-site-verification"/>
<link href="http://purl.org/dc/terms/" rel="schema.DCTERMS">
<link href="http://purl.org/dc/elements/1.1/" rel="schema.DC">
<meta content="Bengio, Yoshua" name="DC.contributor">
<meta content="Serdyuk, Dmitriy" name="DC.creator">
<meta content="2021-02-11T19:59:35Z" name="DCTERMS.dateAccepted" scheme="DCTERMS.W3CDTF">
<meta content="NO_RESTRICTION" name="DCTERMS.available" scheme="DCTERMS.W3CDTF" xml:lang="fr">
<meta content="2021-02-11T19:59:35Z" name="DCTERMS.available" scheme="DCTERMS.W3CDTF">
<meta content="2020-12-16" name="DCTERMS.issued" scheme="DCTERMS.W3CDTF">
<meta content="2020-10" name="DC.date" scheme="DCTERMS.W3CDTF"/>
<meta content="http://hdl.handle.net/1866/24803" name="DC.identifier" scheme="DCTERMS.URI"/>
<meta content="Deep learning" name="DC.subject" xml:lang="fr"/>
<meta content="Machine learning" name="DC.subject" xml:lang="fr"/>
<meta content="Speech recognition" name="DC.subject" xml:lang="fr"/>
<meta content="Neural networks" name="DC.subject" xml:lang="fr"/>
<meta content="Domain adaptation" name="DC.subject" xml:lang="fr"/>
<meta content="Noisy speech recognition" name="DC.subject" xml:lang="fr"/>
<meta content="Adversarial learning" name="DC.subject" xml:lang="fr"/>
<meta content="Recurrent neural networks" name="DC.subject" xml:lang="fr"/>
<meta content="Sequence generation" name="DC.subject" xml:lang="fr"/>
<meta content="Spoken language understanding" name="DC.subject" xml:lang="fr"/>
<meta content="End-to-end learning" name="DC.subject" xml:lang="fr"/>
<meta content="Apprentissage profond" name="DC.subject" xml:lang="fr"/>
<meta content="Apprentissage automatique" name="DC.subject" xml:lang="fr"/>
<meta content="Reconnaissance de la parole" name="DC.subject" xml:lang="fr"/>
<meta content="Réseaux de neurones" name="DC.subject" xml:lang="fr"/>
<meta content="Adaptation de domaine" name="DC.subject" xml:lang="fr"/>
<meta content="Reconnaissance de la parole bruyante" name="DC.subject" xml:lang="fr"/>
<meta content="Apprentissage antogoniste" name="DC.subject" xml:lang="fr"/>
<meta content="Réseaux de neurones récurrents" name="DC.subject" xml:lang="fr"/>
<meta content="Génération de séquences" name="DC.subject" xml:lang="fr"/>
<meta content="Compréhension du langage vocal" name="DC.subject" xml:lang="fr"/>
<meta content="Apprentissage de bout en bout" name="DC.subject" xml:lang="fr"/>
<meta content="Applied Sciences - Artificial Intelligence / Sciences appliqués et technologie - Intelligence artificielle (UMI : 0800)" name="DC.subject" xml:lang="fr"/>
<meta content="Advances in deep learning methods for speech recognition and understanding" name="DC.title" xml:lang="fr"/>
<meta content="Thèse ou mémoire / Thesis or Dissertation" name="DC.type"/>
<meta content="Ce travail expose plusieurs études dans les domaines de
    la reconnaissance de la parole et
    compréhension du langage parlé.
    La compréhension sémantique du langage parlé est un sous-domaine important
    de l'intelligence artificielle.
    Le traitement de la parole intéresse depuis longtemps les chercheurs,
    puisque la parole est une des charactéristiques qui definit l'être humain.
    Avec le développement du réseau neuronal artificiel,
    le domaine a connu une évolution rapide
    à la fois en terme de précision et de perception humaine.
    Une autre étape importante a été franchie avec le développement
    d'approches bout en bout.
    De telles approches permettent une coadaptation de toutes
    les parties du modèle, ce qui augmente ainsi les performances,
    et ce qui simplifie la procédure d'entrainement.
    Les modèles de bout en bout sont devenus réalisables avec la quantité croissante
    de données disponibles, de ressources informatiques et,
    surtout, avec de nombreux développements architecturaux innovateurs.
    Néanmoins, les approches traditionnelles (qui ne sont pas bout en bout)
    sont toujours pertinentes pour le traitement de la parole en raison
    des données difficiles dans les environnements bruyants,
    de la parole avec un accent et de la grande variété de dialectes.

    Dans le premier travail, nous explorons la reconnaissance de la parole hybride
    dans des environnements bruyants.
    Nous proposons de traiter la reconnaissance de la parole,
    qui fonctionne dans
    un nouvel environnement composé de différents bruits inconnus,
    comme une tâche d'adaptation de domaine.
    Pour cela, nous utilisons la nouvelle technique à l'époque
    de l'adaptation du domaine antagoniste.
    En résumé, ces travaux antérieurs proposaient de former
    des caractéristiques de manière à ce qu'elles soient distinctives
    pour la tâche principale, mais non-distinctive pour la tâche secondaire.
    Cette tâche secondaire est conçue pour être la tâche de reconnaissance de domaine.
    Ainsi, les fonctionnalités entraînées sont invariantes vis-à-vis du domaine considéré.
    Dans notre travail, nous adoptons cette technique et la modifions pour
    la tâche de reconnaissance de la parole dans un environnement bruyant.

    Dans le second travail, nous développons une méthode générale
    pour la régularisation des réseaux génératif récurrents.
    Il est connu que les réseaux récurrents ont souvent des difficultés à rester
    sur le même chemin, lors de la production de sorties longues.
    Bien qu'il soit possible d'utiliser des réseaux bidirectionnels pour
    une meilleure traitement de séquences pour l'apprentissage des charactéristiques,
    qui n'est pas applicable au cas génératif.
    Nous avons développé un moyen d'améliorer la cohérence de
    la production de longues séquences avec des réseaux récurrents.
    Nous proposons un moyen de construire un modèle similaire à un réseau bidirectionnel.
    L'idée centrale est d'utiliser une perte L2 entre
    les réseaux récurrents génératifs vers l'avant et vers l'arrière.
    Nous fournissons une évaluation expérimentale sur
    une multitude de tâches et d'ensembles de données,
    y compris la reconnaissance vocale,
    le sous-titrage d'images et la modélisation du langage.

    Dans le troisième article, nous étudions la possibilité de développer
    un identificateur d'intention de bout en bout pour la compréhension du langage parlé.
    La compréhension sémantique du langage parlé est une étape importante vers
    le développement d'une intelligence artificielle de type humain.
    Nous avons vu que les approches de bout en bout montrent
    des performances élevées sur les tâches, y compris la traduction automatique et
    la reconnaissance de la parole.
    Nous nous inspirons des travaux antérieurs pour développer
    un système de bout en bout pour la reconnaissance de l'intention." name="DCTERMS.abstract" xml:lang="fr"/>
<meta content="This work presents several studies in the areas of speech recognition and
    understanding.
    The semantic speech understanding is an important sub-domain of the
    broader field of artificial intelligence.
    Speech processing has had interest from the researchers for long time
    because language is one of the defining characteristics of a human being.
    With the development of neural networks, the domain has seen rapid progress
    both in terms of accuracy and human perception.
    Another important milestone was achieved with the development of
    end-to-end approaches.
    Such approaches allow co-adaptation of all the parts of the model
    thus increasing the performance, as well as simplifying the training
    procedure.
    End-to-end models became feasible with the increasing amount of available
    data, computational resources, and most importantly with many novel
    architectural developments.
    Nevertheless, traditional, non end-to-end, approaches are still relevant
    for speech processing due to challenging data in noisy environments,
    accented speech, and high variety of dialects.

    In the first work, we explore the hybrid speech recognition in noisy
    environments.
    We propose to treat the recognition in the unseen noise condition
    as the domain adaptation task.
    For this, we use the novel at the time technique of the adversarial
    domain adaptation.
    In the nutshell, this prior work proposed to train features in such
    a way that they are discriminative for the primary task,
    but non-discriminative for the secondary task.
    This secondary task is constructed to be the domain recognition task.
    Thus, the features trained are invariant towards the domain at hand.
    In our work, we adopt this technique and modify it for the task of
    noisy speech recognition.

    In the second work, we develop a general method for regularizing
    the generative recurrent networks.
    It is known that the recurrent networks frequently have difficulties
    staying on same track when generating long outputs.
    While it is possible to use bi-directional networks for better
    sequence aggregation for feature learning, it is not applicable
    for the generative case.
    We developed a way improve the consistency of generating long sequences
    with recurrent networks.
    We propose a way to construct a model similar to bi-directional network.
    The key insight is to use a soft L2 loss between the forward and
    the backward generative recurrent networks.
    We provide experimental evaluation on a multitude of tasks and datasets,
    including speech recognition, image captioning, and language modeling.

    In the third paper, we investigate the possibility of developing
    an end-to-end intent recognizer for spoken language understanding.
    The semantic spoken language understanding is an important
    step towards developing a human-like artificial intelligence.
    We have seen that the end-to-end approaches show high
    performance on the tasks including machine translation and speech recognition.
    We draw the inspiration from the prior works to develop
    an end-to-end system for intent recognition." name="DCTERMS.abstract" xml:lang="fr"/>
<meta content="eng" name="DCTERMS.language" xml:lang="fr"/>
<meta content="Deep learning; Machine learning; Speech recognition; Neural networks; Domain adaptation; Noisy speech recognition; Adversarial learning; Recurrent neural networks; Sequence generation; Spoken language understanding; End-to-end learning; Apprentissage profond; Apprentissage automatique; Reconnaissance de la parole; Réseaux de neurones; Adaptation de domaine; Reconnaissance de la parole bruyante; Apprentissage antogoniste; Réseaux de neurones récurrents; Génération de séquences; Compréhension du langage vocal; Apprentissage de bout en bout; Applied Sciences - Artificial Intelligence / Sciences appliqués et technologie - Intelligence artificielle (UMI : 0800); Thèse ou mémoire / Thesis or Dissertation; Informatique" name="citation_keywords"/>
<meta content="Advances in deep learning methods for speech recognition and understanding" name="citation_title"/>
<meta content="eng" name="citation_language"/>
<meta content="Serdyuk, Dmitriy" name="citation_author"/>
<meta content="https://papyrus.bib.umontreal.ca/xmlui/bitstream/1866/24803/8/Serdyuk_Dmitriy_2020_These.pdf" name="citation_pdf_url"/>
<meta content="2020-12-16" name="citation_date"/>
<meta content="https://papyrus.bib.umontreal.ca/xmlui/handle/1866/24803" name="citation_abstract_html_url"/>
<script type="text/x-mathjax-config">
                    MathJax.Hub.Config({
                      tex2jax: {
                        inlineMath: [['\\(','\\)']],
                        ignoreClass: "detail-field-data|detailtable|exception"
                      },
                      TeX: {
                        Macros: {
                          AA: '{\\mathring A}'
                        }
                      }
                    });
                </script><script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"> </script>
</meta></meta></meta></meta></meta></meta></link></link></head><body>
<header>
<div class="navbar navbar-default navbar-static-top" role="navigation">
<div class="container">
<div class="hidden-xs hidden-sm hidden-md" id="um-bandeau" role="banner">
<nav class="um-nav um-nav-hidden" role="navigation">
<span class="hidden">Liens externes</span>
<ul>
<li>
<a href="https://www.umontreal.ca/#udemwww-search-personne">Directories</a>
</li>
<li>
<a href="http://www.umontreal.ca/repertoires/facultes.html">Faculties</a>
</li>
<li>
<a href="http://www.bib.umontreal.ca/">Libraries</a>
</li>
<li>
<a href="http://plancampus.umontreal.ca/">Campus maps</a>
</li>
<li>
<a href="http://www.umontreal.ca/index/az.html">Sites A to Z</a>
</li>
<li>
<a>My UdeM</a>
<ul>
<li>
<a href="https://monudem.umontreal.ca/">My UdeM Portal</a>
</li>
<li>
<a href="https://outlook.umontreal.ca">My email</a>
</li>
<li>
<a href="https://studium.umontreal.ca/">StudiUM</a>
</li>
</ul>
</li>
</ul>
</nav>
<form action="https://google.com/cse" class="um-recherche" id="um-recherche" role="search">
<input name="cx" type="hidden" value="011926736769028447783:qlpu3so2kqq"/><input name="ie" type="hidden" value="ISO-8859-1"/><label class="hidden" for="um-boite-recherche">Search in : </label><span class="um-boite-bouton"><input class="um-boite" id="um-boite-recherche" maxlength="255" name="q" placeholder="UdeM" title="Type your search text" type="text" value=""/><input alt="Search in : " class="um-bouton" src="/xmlui/themes/Mirage2/images/bib-umontreal/loupe.gif" type="image"/></span>
</form>
</div>
<div class="hidden-xs hidden-sm visible-md visible-lg" id="papyrus-deco">
<img alt="Dessin du pavillon Roger Gaudry/Sketch of Roger Gaudry Building" border="0" height="89px" src="/xmlui/themes/Mirage2/images/UdeM.gif" title="Dessin du pavillon Roger Gaudry/Sketch of Roger Gaudry Building" width="193px"/></div>
<div class="navbar-header">
<button class="navbar-toggle" data-toggle="offcanvas" type="button"><span class="sr-only">Toggle navigation</span><span class="icon-bar"></span><span class="icon-bar"></span><span class="icon-bar"></span></button><a class="navbar-brand hidden-xs hidden-sm visible-md visible-lg um-logo-md-lg" href="http://www.umontreal.ca/english/index.html"><img alt="University Home page" src="/xmlui/themes/Mirage2/images/logo-UdeM.svg" title="Back to University Home page"/></a><a class="navbar-brand hidden-xs visible-sm hidden-md hidden-lg um-logo-sm" href="http://www.umontreal.ca/english/index.html"><img alt="University Home page" src="/xmlui/themes/Mirage2/images/logo-UdeM.svg" title="Back to University Home page"/></a><a class="navbar-brand visible-xs hidden-sm hidden-md hidden-lg um-logo-xs" href="http://www.umontreal.ca/english/index.html"><img alt="University Home page" src="/xmlui/themes/Mirage2/images/logo-UdeM.svg" title="Back to University Home page"/></a>
<div class="navbar-brand separateur visible-xs hidden-sm hidden-md hidden-lg um-sep-site-xs"></div>
<div class="navbar-brand separateur hidden-xs visible-sm hidden-md hidden-lg um-sep-site-sm"></div>
<div class="navbar-brand separateur visible-md visible-lg hidden-xs hidden-sm um-sep-site-md-lg"></div>
<div class="navbar-brand visible-md visible-lg hidden-xs hidden-sm um-titre-site-md-lg">
<span class="papyrus-signature">Papyrus</span> :
                                Institutional Repository</div>
<div class="navbar-brand hidden-xs visible-sm hidden-md hidden-lg um-titre-site-sm">
<span class="papyrus-signature">Papyrus</span>
<br/>Institutional Repository</div>
<div class="navbar-brand visible-xs hidden-sm hidden-md hidden-lg um-titre-site-xs">
<span class="papyrus-signature">Papyrus</span>
</div>
<div class="navbar-header pull-right visible-xs hidden-sm hidden-md hidden-lg">
<ul class="nav nav-pills pull-left">
<li class="dropdown" id="ds-language-selection-xs">
<button class="dropdown-toggle navbar-toggle navbar-link" data-toggle="dropdown" href="#" id="language-dropdown-toggle-xs" role="button"><b aria-hidden="true" class="visible-xs glyphicon glyphicon-globe"></b></button>
<ul aria-labelledby="language-dropdown-toggle-xs" class="dropdown-menu pull-right" data-no-collapse="true" role="menu">
<li role="presentation">
<a href="https://papyrus.bib.umontreal.ca:443/xmlui/handle/1866/24803?locale-attribute=fr&amp;show=full">français</a>
</li>
<li class="disabled" role="presentation">
<a href="https://papyrus.bib.umontreal.ca:443/xmlui/handle/1866/24803?locale-attribute=en&amp;show=full">English</a>
</li>
</ul>
</li>
<li>
<form action="/xmlui/login" method="get" style="display: inline">
<button class="navbar-toggle navbar-link"><b aria-hidden="true" class="visible-xs glyphicon glyphicon-user"></b></button>
</form>
</li>
</ul>
</div>
</div>
<div class="navbar-header pull-right hidden-xs">
<div class="nav-language-and-login-lg hidden-xs hidden-sm hidden-md">
<ul class="nav navbar-nav pull-right">
<li class="dropdown" id="ds-language-selection">
<a class="dropdown-toggle" data-toggle="dropdown" href="#" id="language-dropdown-toggle" role="button"><span class="hidden-xs">English <b class="caret"></b></span></a>
<ul aria-labelledby="language-dropdown-toggle" class="dropdown-menu pull-right" data-no-collapse="true" role="menu">
<li role="presentation">
<a href="https://papyrus.bib.umontreal.ca:443/xmlui/handle/1866/24803?locale-attribute=fr&amp;show=full">français</a>
</li>
<li class="disabled" role="presentation">
<a href="https://papyrus.bib.umontreal.ca:443/xmlui/handle/1866/24803?locale-attribute=en&amp;show=full">English</a>
</li>
</ul>
</li>
</ul>
<ul class="nav navbar-nav pull-right">
<li>
<a href="/xmlui/login"><span class="hidden-xs">Login</span></a>
</li>
</ul>
</div>
<div class="hidden-lg">
<ul class="nav navbar-nav pull-right">
<li class="dropdown" id="ds-language-selection">
<a class="dropdown-toggle" data-toggle="dropdown" href="#" id="language-dropdown-toggle" role="button"><span class="hidden-xs">English <b class="caret"></b></span></a>
<ul aria-labelledby="language-dropdown-toggle" class="dropdown-menu pull-right" data-no-collapse="true" role="menu">
<li role="presentation">
<a href="https://papyrus.bib.umontreal.ca:443/xmlui/handle/1866/24803?locale-attribute=fr&amp;show=full">français</a>
</li>
<li class="disabled" role="presentation">
<a href="https://papyrus.bib.umontreal.ca:443/xmlui/handle/1866/24803?locale-attribute=en&amp;show=full">English</a>
</li>
</ul>
</li>
</ul>
<ul class="nav navbar-nav pull-right">
<li>
<a href="/xmlui/login"><span class="hidden-xs">Login</span></a>
</li>
</ul>
</div>
<button class="navbar-toggle visible-sm" data-toggle="offcanvas" type="button"><span class="sr-only">Toggle navigation</span><span class="icon-bar"></span><span class="icon-bar"></span><span class="icon-bar"></span></button>
</div>
</div>
</div>
</header>
<div class="trail-wrapper hidden-print">
<div class="container">
<div class="row">
<div class="col-xs-12">
<div class="breadcrumb dropdown visible-xs">
<a class="dropdown-toggle" data-toggle="dropdown" href="#" id="trail-dropdown-toggle" role="button">View Item <b class="caret"></b></a>
<ul aria-labelledby="trail-dropdown-toggle" class="dropdown-menu" role="menu">
<li role="presentation">
<a href="/xmlui/" role="menuitem"><i aria-hidden="true" class="glyphicon glyphicon-home"></i>  Home</a>
</li>
<li role="presentation">
<a href="/xmlui/handle/1866/3010" role="menuitem">Faculté des arts et des sciences</a>
</li>
<li role="presentation">
<a href="/xmlui/handle/1866/2958" role="menuitem">Faculté des arts et des sciences – Département d'informatique et de recherche opérationnelle</a>
</li>
<li role="presentation">
<a href="/xmlui/handle/1866/3001" role="menuitem">Faculté des arts et des sciences – Département d'informatique et de recherche opérationnelle - Thèses et mémoires</a>
</li>
<li class="disabled" role="presentation">
<a href="#" role="menuitem">View Item</a>
</li>
</ul>
</div>
<ul class="breadcrumb hidden-xs">
<li>
<i aria-hidden="true" class="glyphicon glyphicon-home"></i>  <a href="/xmlui/">Home</a>
</li>
<li>
<a href="/xmlui/handle/1866/3010">Faculté des arts et des sciences</a>
</li>
<li>
<a href="/xmlui/handle/1866/2958">Faculté des arts et des sciences – Département d'informatique et de recherche opérationnelle</a>
</li>
<li>
<a href="/xmlui/handle/1866/3001">Faculté des arts et des sciences – Département d'informatique et de recherche opérationnelle - Thèses et mémoires</a>
</li>
<li class="active">View Item</li>
</ul>
</div>
</div>
</div>
</div>
<div class="hidden" id="no-js-warning-wrapper">
<div id="no-js-warning">
<div class="notice failure">JavaScript is disabled for your browser. Some features of this site may not work without it.</div>
</div>
</div>
<div class="container" id="main-container">
<div class="row row-offcanvas row-offcanvas-left">
<div class="horizontal-slider clearfix">
<div class="col-xs-6 col-sm-3 sidebar-offcanvas" id="sidebar" role="navigation">
<div class="word-break hidden-print" id="ds-options">
<div class="ds-option-set" id="ds-search-option">
<form action="/xmlui/discover" class="" id="ds-search-form" method="post">
<fieldset>
<div class="input-group">
<input class="ds-text-field form-control" name="query" placeholder="Search" type="text"/><span class="input-group-btn"><button class="ds-button-field btn" title="Go"><span aria-hidden="true" class="glyphicon glyphicon-search"></span></button></span>
</div>
<div class="radio">
<label><input checked="" id="ds-search-form-scope-all" name="scope" type="radio" value=""/>Search Papyrus</label>
</div>
<div class="radio">
<label><input id="ds-search-form-scope-container" name="scope" type="radio" value="1866/3001"/>Search this Collection</label>
</div>
</fieldset>
</form>
</div>
<h2 class="ds-option-set-head h6">My Account</h2>
<div class="list-group" id="aspect_viewArtifacts_Navigation_list_account">
<div class="list-group-item ds-option details_Papyrus" id="aspect_eperson_Navigation_item_details_Papyrus">To submit an item or subscribe to email alerts.</div>
<div class="list-group-item ds-option">
<span class="bold"><a href="/xmlui/login">Login</a></span>
</div>
<a class="list-group-item ds-option" href="/xmlui/register">New user?</a>
</div>
<h2 class="ds-option-set-head h6">Browse</h2>
<div class="list-group" id="aspect_viewArtifacts_Navigation_list_browse">
<a class="list-group-item active"><span class="h5 list-group-item-heading h5">All of Papyrus</span></a><a class="list-group-item ds-option" href="/xmlui/community-list">Communities and Collections</a><a class="list-group-item ds-option" href="/xmlui/browse?type=title">Titles</a><a class="list-group-item ds-option" href="/xmlui/browse?type=dateissued">Issue Dates</a><a class="list-group-item ds-option" href="/xmlui/browse?type=author">Authors</a><a class="list-group-item ds-option" href="/xmlui/browse?type=advisor">Advisors</a><a class="list-group-item ds-option" href="/xmlui/browse?type=subject">Subjects</a><a class="list-group-item ds-option" href="/xmlui/browse?type=discipline">Disciplines</a><a class="list-group-item ds-option" href="/xmlui/browse?type=affiliation">Affiliation</a><a class="list-group-item ds-option" href="/xmlui/browse?type=titleindex">Titles index</a><a class="list-group-item active"><span class="h5 list-group-item-heading h5">This Collection</span></a><a class="list-group-item ds-option" href="/xmlui/handle/1866/3001/browse?type=title">Titles</a><a class="list-group-item ds-option" href="/xmlui/handle/1866/3001/browse?type=dateissued">Issue Dates</a><a class="list-group-item ds-option" href="/xmlui/handle/1866/3001/browse?type=author">Authors</a><a class="list-group-item ds-option" href="/xmlui/handle/1866/3001/browse?type=advisor">Advisors</a><a class="list-group-item ds-option" href="/xmlui/handle/1866/3001/browse?type=subject">Subjects</a><a class="list-group-item ds-option" href="/xmlui/handle/1866/3001/browse?type=discipline">Disciplines</a><a class="list-group-item ds-option" href="/xmlui/handle/1866/3001/browse?type=affiliation">Affiliation</a><a class="list-group-item ds-option" href="/xmlui/handle/1866/3001/browse?type=titleindex">Titles index</a>
</div>
<div class="list-group" id="aspect_viewArtifacts_Navigation_list_context"></div>
<div class="list-group" id="aspect_viewArtifacts_Navigation_list_administrative"></div>
<div class="list-group" id="aspect_discovery_Navigation_list_discovery"></div>
<h2 class="ds-option-set-head h6">Statistics</h2>
<div class="list-group" id="aspect_statistics_Navigation_list_statistics">
<a class="list-group-item ds-option" href="/xmlui/handle/1866/24803/statistics">View Usage Statistics</a>
</div>
</div>
</div>
<div class="col-xs-12 col-sm-12 col-md-9 main-content">
<div>
<div class="ds-static-div primary" id="aspect_artifactbrowser_ItemViewer_div_item-view">
<p class="ds-paragraph item-view-toggle item-view-toggle-top">
<span class="item-view-toggle"><a href="/xmlui/handle/1866/24803">Show item record</a></span>
</p>
<!-- External Metadata URL: cocoon://metadata/handle/1866/24803/mets.xml-->
<h2 class="page-header first-page-header">Advances in deep learning methods for speech recognition and understanding</h2>
<div class="ds-table-responsive">
<table class="ds-includeSet-table detailtable table table-striped table-hover">
<tr class="ds-table-row odd">
<td class="label-cell">dc.contributor.advisor</td><td class="word-break">Bengio, Yoshua</td><td></td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.contributor.author</td><td class="word-break">Serdyuk, Dmitriy</td><td></td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.date.accessioned</td><td class="word-break">2021-02-11T19:59:35Z</td><td></td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.date.available</td><td class="word-break">NO_RESTRICTION</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.date.available</td><td class="word-break">2021-02-11T19:59:35Z</td><td></td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.date.issued</td><td class="word-break">2020-12-16</td><td></td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.date.submitted</td><td class="word-break">2020-10</td><td></td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.identifier.uri</td><td class="word-break">http://hdl.handle.net/1866/24803</td><td></td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject</td><td class="word-break">Deep learning</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">Machine learning</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject</td><td class="word-break">Speech recognition</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">Neural networks</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject</td><td class="word-break">Domain adaptation</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">Noisy speech recognition</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject</td><td class="word-break">Adversarial learning</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">Recurrent neural networks</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject</td><td class="word-break">Sequence generation</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">Spoken language understanding</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject</td><td class="word-break">End-to-end learning</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">Apprentissage profond</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject</td><td class="word-break">Apprentissage automatique</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">Reconnaissance de la parole</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject</td><td class="word-break">Réseaux de neurones</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">Adaptation de domaine</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject</td><td class="word-break">Reconnaissance de la parole bruyante</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">Apprentissage antogoniste</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject</td><td class="word-break">Réseaux de neurones récurrents</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">Génération de séquences</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject</td><td class="word-break">Compréhension du langage vocal</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.subject</td><td class="word-break">Apprentissage de bout en bout</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.subject.other</td><td class="word-break">Applied Sciences - Artificial Intelligence / Sciences appliqués et technologie - Intelligence artificielle (UMI : 0800)</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dc.title</td><td class="word-break">Advances in deep learning methods for speech recognition and understanding</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dc.type</td><td class="word-break">Thèse ou mémoire / Thesis or Dissertation</td><td></td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">etd.degree.discipline</td><td class="word-break">Informatique</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">etd.degree.grantor</td><td class="word-break">Université de Montréal</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">etd.degree.level</td><td class="word-break">Doctorat / Doctoral</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">etd.degree.name</td><td class="word-break">Ph. D.</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dcterms.abstract</td><td class="word-break">Ce travail expose plusieurs études dans les domaines de
    la reconnaissance de la parole et
    compréhension du langage parlé.
    La compréhension sémantique du langage parlé est un sous-domaine important
    de l'intelligence artificielle.
    Le traitement de la parole intéresse depuis longtemps les chercheurs,
    puisque la parole est une des charactéristiques qui definit l'être humain.
    Avec le développement du réseau neuronal artificiel,
    le domaine a connu une évolution rapide
    à la fois en terme de précision et de perception humaine.
    Une autre étape importante a été franchie avec le développement
    d'approches bout en bout.
    De telles approches permettent une coadaptation de toutes
    les parties du modèle, ce qui augmente ainsi les performances,
    et ce qui simplifie la procédure d'entrainement.
    Les modèles de bout en bout sont devenus réalisables avec la quantité croissante
    de données disponibles, de ressources informatiques et,
    surtout, avec de nombreux développements architecturaux innovateurs.
    Néanmoins, les approches traditionnelles (qui ne sont pas bout en bout)
    sont toujours pertinentes pour le traitement de la parole en raison
    des données difficiles dans les environnements bruyants,
    de la parole avec un accent et de la grande variété de dialectes.

    Dans le premier travail, nous explorons la reconnaissance de la parole hybride
    dans des environnements bruyants.
    Nous proposons de traiter la reconnaissance de la parole,
    qui fonctionne dans
    un nouvel environnement composé de différents bruits inconnus,
    comme une tâche d'adaptation de domaine.
    Pour cela, nous utilisons la nouvelle technique à l'époque
    de l'adaptation du domaine antagoniste.
    En résumé, ces travaux antérieurs proposaient de former
    des caractéristiques de manière à ce qu'elles soient distinctives
    pour la tâche principale, mais non-distinctive pour la tâche secondaire.
    Cette tâche secondaire est conçue pour être la tâche de reconnaissance de domaine.
    Ainsi, les fonctionnalités entraînées sont invariantes vis-à-vis du domaine considéré.
    Dans notre travail, nous adoptons cette technique et la modifions pour
    la tâche de reconnaissance de la parole dans un environnement bruyant.

    Dans le second travail, nous développons une méthode générale
    pour la régularisation des réseaux génératif récurrents.
    Il est connu que les réseaux récurrents ont souvent des difficultés à rester
    sur le même chemin, lors de la production de sorties longues.
    Bien qu'il soit possible d'utiliser des réseaux bidirectionnels pour
    une meilleure traitement de séquences pour l'apprentissage des charactéristiques,
    qui n'est pas applicable au cas génératif.
    Nous avons développé un moyen d'améliorer la cohérence de
    la production de longues séquences avec des réseaux récurrents.
    Nous proposons un moyen de construire un modèle similaire à un réseau bidirectionnel.
    L'idée centrale est d'utiliser une perte L2 entre
    les réseaux récurrents génératifs vers l'avant et vers l'arrière.
    Nous fournissons une évaluation expérimentale sur
    une multitude de tâches et d'ensembles de données,
    y compris la reconnaissance vocale,
    le sous-titrage d'images et la modélisation du langage.

    Dans le troisième article, nous étudions la possibilité de développer
    un identificateur d'intention de bout en bout pour la compréhension du langage parlé.
    La compréhension sémantique du langage parlé est une étape importante vers
    le développement d'une intelligence artificielle de type humain.
    Nous avons vu que les approches de bout en bout montrent
    des performances élevées sur les tâches, y compris la traduction automatique et
    la reconnaissance de la parole.
    Nous nous inspirons des travaux antérieurs pour développer
    un système de bout en bout pour la reconnaissance de l'intention.</td><td>fr</td>
</tr>
<tr class="ds-table-row odd">
<td class="label-cell">dcterms.abstract</td><td class="word-break">This work presents several studies in the areas of speech recognition and
    understanding.
    The semantic speech understanding is an important sub-domain of the
    broader field of artificial intelligence.
    Speech processing has had interest from the researchers for long time
    because language is one of the defining characteristics of a human being.
    With the development of neural networks, the domain has seen rapid progress
    both in terms of accuracy and human perception.
    Another important milestone was achieved with the development of
    end-to-end approaches.
    Such approaches allow co-adaptation of all the parts of the model
    thus increasing the performance, as well as simplifying the training
    procedure.
    End-to-end models became feasible with the increasing amount of available
    data, computational resources, and most importantly with many novel
    architectural developments.
    Nevertheless, traditional, non end-to-end, approaches are still relevant
    for speech processing due to challenging data in noisy environments,
    accented speech, and high variety of dialects.

    In the first work, we explore the hybrid speech recognition in noisy
    environments.
    We propose to treat the recognition in the unseen noise condition
    as the domain adaptation task.
    For this, we use the novel at the time technique of the adversarial
    domain adaptation.
    In the nutshell, this prior work proposed to train features in such
    a way that they are discriminative for the primary task,
    but non-discriminative for the secondary task.
    This secondary task is constructed to be the domain recognition task.
    Thus, the features trained are invariant towards the domain at hand.
    In our work, we adopt this technique and modify it for the task of
    noisy speech recognition.

    In the second work, we develop a general method for regularizing
    the generative recurrent networks.
    It is known that the recurrent networks frequently have difficulties
    staying on same track when generating long outputs.
    While it is possible to use bi-directional networks for better
    sequence aggregation for feature learning, it is not applicable
    for the generative case.
    We developed a way improve the consistency of generating long sequences
    with recurrent networks.
    We propose a way to construct a model similar to bi-directional network.
    The key insight is to use a soft L2 loss between the forward and
    the backward generative recurrent networks.
    We provide experimental evaluation on a multitude of tasks and datasets,
    including speech recognition, image captioning, and language modeling.

    In the third paper, we investigate the possibility of developing
    an end-to-end intent recognizer for spoken language understanding.
    The semantic spoken language understanding is an important
    step towards developing a human-like artificial intelligence.
    We have seen that the end-to-end approaches show high
    performance on the tasks including machine translation and speech recognition.
    We draw the inspiration from the prior works to develop
    an end-to-end system for intent recognition.</td><td>fr</td>
</tr>
<tr class="ds-table-row even">
<td class="label-cell">dcterms.language</td><td class="word-break">eng</td><td>fr</td>
</tr>
</table>
</div>
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc&amp;rft_id=http%3A%2F%2Fhdl.handle.net%2F1866%2F24803&amp;rfr_id=info%3Asid%2Fdspace.org%3Arepository&amp;rft.degree=Informatique&amp;rft.degree=Universit%C3%A9+de+Montr%C3%A9al&amp;rft.degree=Doctorat+%2F+Doctoral&amp;rft.degree=Ph.+D."> ﻿ 
        </span>
<h3>Files in this item</h3>
<div class="file-list">
<div class="file-wrapper row">
<div class="col-xs-6 col-sm-3">
<div class="thumbnail-wrapper">
<a class="image-link" href="/xmlui/bitstream/handle/1866/24803/Serdyuk_Dmitriy_2020_These.pdf?sequence=8&amp;isAllowed=y"><img alt="Thumbnail" class="thumbnail-papyrus" src="/xmlui/bitstream/handle/1866/24803/Serdyuk_Dmitriy_2020_These.pdf.jpg?sequence=10&amp;isAllowed=y"/></a>
<div class="imageoverlay">
<img height="49" src="/xmlui/themes/Mirage2/images/mimes/mime_icone_pdf.png" style="height: 49px;" width="44"/></div>
</div>
</div>
<div class="col-xs-6 col-sm-7">
<dl class="file-metadata dl-horizontal">
<dt>Name:</dt>
<dd class="word-break" title="Serdyuk_Dmitriy_2020_These.pdf">
<a href="/xmlui/bitstream/handle/1866/24803/Serdyuk_Dmitriy_2020_These.pdf?sequence=8&amp;isAllowed=y">Serdyuk_Dmitriy_2020_These.pdf</a>
</dd>
<dt>Size:</dt>
<dd class="word-break">2.605Mb</dd>
<dt>Format:</dt>
<dd class="word-break">PDF</dd>
<dt>Description:</dt>
<dd class="word-break" title="Thèse">Thèse</dd>
</dl>
</div>
</div>
</div>
<h3 class="ds-list-head">This item appears in the following Collection(s)</h3>
<ul class="ds-referenceSet-list">
<!-- External Metadata URL: cocoon://metadata/handle/1866/2621/mets.xml-->
<li>
<a href="/xmlui/handle/1866/2621">Thèses et mémoires électroniques de l’Université de Montréal</a> [18270]<br/>
</li>
<!-- External Metadata URL: cocoon://metadata/handle/1866/3001/mets.xml-->
<li>
<a href="/xmlui/handle/1866/3001">Faculté des arts et des sciences – Département d'informatique et de recherche opérationnelle - Thèses et mémoires</a> [795]<br/>
</li>
</ul>
<p class="ds-paragraph item-view-toggle item-view-toggle-bottom">
<span class="item-view-toggle"><a href="/xmlui/handle/1866/24803">Show item record</a></span>
</p>
</div>
</div>
<div class="visible-xs visible-sm">
<footer>
<div class="row">
<hr/>
<div class="col-xs-7 col-sm-8">
<div>
<a href="http://www.dspace.org/" target="_blank">DSpace software</a>
                        [version 5.8 XMLUI],
                        copyright © 2002-2015  <a href="http://www.duraspace.org/" target="_blank">DuraSpace</a>
</div>
<div class="hidden-print">
<a href="/xmlui/contact">Contact Us</a> | <a href="/xmlui/feedback">Send Feedback</a>
</div>
</div>
<div class="col-xs-5 col-sm-4 hidden-print">
<div class="pull-right">
<script type="text/javascript"> 
										      (function(d, t) { 
										        var s = d.createElement(t), options = {'domain':'papyrus.bib.umontreal.ca','style': '16','container':'entrust-net-seal'}; 
										        s.src = 'https://seal.entrust.net/sealv2.js'; 
										        s.async = true; 
										        var scr = d.getElementsByTagName(t)[0], par = scr.parentNode; par.insertBefore(s, scr); 
										        s.onload = s.onreadystatechange = function() { 
										        var rs = this.readyState; if (rs) if (rs != 'complete') if (rs != 'loaded') return; 
										        try{goEntrust(options)} catch (e) {} }; 
										        })(document, 'script'); 
										</script>
<div id="entrust-net-seal">
<a href="https://www.entrust.com/ssl-certificates/">Certificat SSL / SSL Certificate</a>
</div>
</div>
</div>
</div>
<div class="row bib-footer hidden-print">
<div class="col-xs-12 col-sm-12 col-md-4">
<a class="footerEXLlink" href="http://www.bib.umontreal.ca"><img alt="les bibliothèques/UdeM" src="/xmlui/themes/Mirage2/images/propulse-par.png"/></a>
</div>
<div class="hidden-xs col-sm-12 col-md-8">
<nav>
<ul>
<li>
<a href="https://www.urgence.umontreal.ca/">Emergency</a>
</li>
<li>
<a href="http://www.carrieres.umontreal.ca/">Careers</a>
</li>
<li>
<a href="https://outlook.umontreal.ca/">My email</a>
</li>
<li>
<a href="https://studium.umontreal.ca/">StudiUM</a>
</li>
<li>
<a href="http://itunesu.umontreal.ca/">iTunes U</a>
</li>
<li>
<a href="http://www.bib.umontreal.ca/a-propos/nous-ecrire.htm">Contact us</a>
</li>
<li>
<a href="https://www.facebook.com/bibUdeM"><img alt="Facebook" src="/xmlui/themes/Mirage2/images/bib-umontreal/logo-Facebook.png"/></a>
</li>
<li>
<a href="https://www.youtube.com/user/BibliothequesUdeM"><img alt="YouTube" src="/xmlui/themes/Mirage2/images/bib-umontreal/logo-YouTube.png"/></a>
</li>
<li>
<a href="https://twitter.com/bibUdeM"><img alt="Twitter" src="/xmlui/themes/Mirage2/images/bib-umontreal/logo-Twitter.png"/></a>
</li>
<li>
<a href="https://www.nouvelles.umontreal.ca/frontpage/rss.html"><img alt="University RSS" src="/xmlui/themes/Mirage2/images/bib-umontreal/icone-syndication-14x14.png"/></a>
</li>
</ul>
</nav>
</div>
</div>
<a class="hidden" href="/xmlui/htmlmap"> </a>
<p> </p>
</footer>
</div>
</div>
</div>
</div>
<div class="hidden-xs hidden-sm">
<footer>
<div class="row">
<hr/>
<div class="col-xs-7 col-sm-8">
<div>
<a href="http://www.dspace.org/" target="_blank">DSpace software</a>
                        [version 5.8 XMLUI],
                        copyright © 2002-2015  <a href="http://www.duraspace.org/" target="_blank">DuraSpace</a>
</div>
<div class="hidden-print">
<a href="/xmlui/contact">Contact Us</a> | <a href="/xmlui/feedback">Send Feedback</a>
</div>
</div>
<div class="col-xs-5 col-sm-4 hidden-print">
<div class="pull-right">
<script type="text/javascript"> 
										      (function(d, t) { 
										        var s = d.createElement(t), options = {'domain':'papyrus.bib.umontreal.ca','style': '16','container':'entrust-net-seal'}; 
										        s.src = 'https://seal.entrust.net/sealv2.js'; 
										        s.async = true; 
										        var scr = d.getElementsByTagName(t)[0], par = scr.parentNode; par.insertBefore(s, scr); 
										        s.onload = s.onreadystatechange = function() { 
										        var rs = this.readyState; if (rs) if (rs != 'complete') if (rs != 'loaded') return; 
										        try{goEntrust(options)} catch (e) {} }; 
										        })(document, 'script'); 
										</script>
<div id="entrust-net-seal">
<a href="https://www.entrust.com/ssl-certificates/">Certificat SSL / SSL Certificate</a>
</div>
</div>
</div>
</div>
<div class="row bib-footer hidden-print">
<div class="col-xs-12 col-sm-12 col-md-4">
<a class="footerEXLlink" href="http://www.bib.umontreal.ca"><img alt="les bibliothèques/UdeM" src="/xmlui/themes/Mirage2/images/propulse-par.png"/></a>
</div>
<div class="hidden-xs col-sm-12 col-md-8">
<nav>
<ul>
<li>
<a href="https://www.urgence.umontreal.ca/">Emergency</a>
</li>
<li>
<a href="http://www.carrieres.umontreal.ca/">Careers</a>
</li>
<li>
<a href="https://outlook.umontreal.ca/">My email</a>
</li>
<li>
<a href="https://studium.umontreal.ca/">StudiUM</a>
</li>
<li>
<a href="http://itunesu.umontreal.ca/">iTunes U</a>
</li>
<li>
<a href="http://www.bib.umontreal.ca/a-propos/nous-ecrire.htm">Contact us</a>
</li>
<li>
<a href="https://www.facebook.com/bibUdeM"><img alt="Facebook" src="/xmlui/themes/Mirage2/images/bib-umontreal/logo-Facebook.png"/></a>
</li>
<li>
<a href="https://www.youtube.com/user/BibliothequesUdeM"><img alt="YouTube" src="/xmlui/themes/Mirage2/images/bib-umontreal/logo-YouTube.png"/></a>
</li>
<li>
<a href="https://twitter.com/bibUdeM"><img alt="Twitter" src="/xmlui/themes/Mirage2/images/bib-umontreal/logo-Twitter.png"/></a>
</li>
<li>
<a href="https://www.nouvelles.umontreal.ca/frontpage/rss.html"><img alt="University RSS" src="/xmlui/themes/Mirage2/images/bib-umontreal/icone-syndication-14x14.png"/></a>
</li>
</ul>
</nav>
</div>
</div>
<a class="hidden" href="/xmlui/htmlmap"> </a>
<p> </p>
</footer>
</div>
</div>
<script src="https://www.google.com/jsapi"> </script><script>if(!window.DSpace){window.DSpace={};}window.DSpace.context_path='/xmlui';window.DSpace.theme_path='/xmlui/themes/Mirage2/';</script><script src="/xmlui/themes/Mirage2/scripts/theme.js"> </script><script>
                  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

                  ga('create', 'UA-305727-1', 'papyrus.bib.umontreal.ca');
                  ga('send', 'pageview');
           </script><script>         
             var details_Papyrus =  $("#aspect_viewArtifacts_Navigation_list_account .details_Papyrus").text();
             $("#aspect_viewArtifacts_Navigation_list_account a[href='/xmlui/login']").attr("title",details_Papyrus);
        </script>
</body></html>
